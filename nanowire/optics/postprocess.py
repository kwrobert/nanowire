import os
import sys
import time
import copy
import logging
import multiprocessing as mp
import matplotlib
try:
    os.environ['DISPLAY']
except KeyError:
    matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.cm as cmx
import matplotlib.lines as mlines
import matplotlib.patches as mpatches
import scipy.constants as c
import scipy.integrate as intg
import numpy as np
np.set_printoptions(precision=3, threshold=100000)
from mpl_toolkits.mplot3d import Axes3D
from itertools import repeat
from collections import OrderedDict
from scipy import interpolate
import scipy.constants as consts
from .utils.config import Config
from .utils.utils import IdFilter, cmp_dicts, make_hash, get_nk
from .data_manager import HDF5DataManager, NPZDataManager
from .utils.geometry import Layer, get_mask, get_layers

# Configure logging for this module
# Get numeric level safely
logfile = 'logs/postprocess.log'
debug = getattr(logging, 'debug'.upper(), None)
info = getattr(logging, 'info'.upper(), None)
# Set formatting
formatter = logging.Formatter('%(asctime)s [%(name)s:%(levelname)s]'
                              ' - %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p')
# Create logger
logger = logging.getLogger(__name__)
logger.setLevel(debug)
log_dir, logfile = os.path.split(os.path.expandvars(logfile))
# Set up file handler
try:
    os.makedirs(log_dir)
except OSError:
    # Log dir already exists
    pass
output_file = os.path.join(log_dir, logfile)
fhandler = logging.FileHandler(output_file)
fhandler.setFormatter(formatter)
fhandler.setLevel(debug)
# We dont want log records generated by Simulation instances making it to the
# global simulate.log file
fhandler.addFilter(IdFilter(reject=True))
logger.addHandler(fhandler)
# Logging to console
ch = logging.StreamHandler()
ch.setLevel(debug)
ch.setFormatter(formatter)
ch.addFilter(IdFilter(reject=True))
logger.addHandler(ch)


# This will log any uncaught exceptions
def handle_exception(exc_type, exc_value, exc_traceback):
    if issubclass(exc_type, KeyboardInterrupt):
        sys.__excepthook__(exc_type, exc_value, exc_traceback)
        return

    logger.critical("Uncaught exception", exc_info=(exc_type, exc_value,
                                                    exc_traceback))


sys.excepthook = handle_exception


class Simulation:
    """
    An object that represents a simulation. It stores a DataManager object for
    managing the reading and writing of all data in the ``self.data``
    attribute. It also stores a Config object, which is a dict-like object
    representing the configuration for the simulation, in the ``self.conf``
    attribute. Many of the methods are for performing calculations on the data.
    """

    def __init__(self, conf=None, simulator=None):
        """
        :param :class:`~utils.config.Config`: Config object for this simulation
        """

        if conf is None and simulator is None:
            raise ValueError('Must pass in either a Config object or a'
                             ' Simulator object')
        if conf is not None:
            self.conf = conf
        else:
            self.conf = copy.deepcopy(simulator.conf)
        self.id = make_hash(self.conf.data)
        self.dir = os.path.expandvars(self.conf['General']['sim_dir'])
        self.fhandler = logging.FileHandler(os.path.join(self.dir, 'postprocess.log'))
        self.fhandler.addFilter(IdFilter(ID=self.id))
        formatter = logging.Formatter('%(asctime)s [%(name)s:%(levelname)s] - %(message)s',datefmt='%m/%d/%Y %I:%M:%S %p')
        self.fhandler.setFormatter(formatter)
        log = logging.getLogger(__name__)
        log.addHandler(self.fhandler)
        # Store the logger adapter to the module level logger as an attribute.
        # We use this to log in any methods, and the sim_id of this instance
        # will get stored in the log record
        self.log = logging.LoggerAdapter(log, {'ID': self.id})
        self.log.debug('Logger initialized')
        if conf is not None:
            self.data = self._get_data_manager()
        else:
            self.data = copy.deepcopy(simulator.data)
        self.failed = False
        self.avgs = {}
        # Compute and store dx, dy, dz at attributes
        self.zsamps = int(self.conf['Simulation']['z_samples'])
        self.xsamps = int(self.conf['Simulation']['x_samples'])
        self.ysamps = int(self.conf['Simulation']['y_samples'])
        self.X = self.data['xcoords']
        self.Y = self.data['ycoords']
        self.Z = self.data['zcoords']
        self.dx = self.X[1] - self.X[0]
        self.dy = self.Y[1] - self.Y[0]
        self.dz = self.Z[1] - self.Z[0]
        self.period = self.conf['Simulation']['params']['array_period']
        self.layers = get_layers(self)
        self.height = self.get_height()

    def _get_data_manager(self):
        """
        Factory function that instantiates the correct data manager object
        depending on the file type specified in the config
        """

        ftype = self.conf['General']['save_as']
        if ftype == 'npz':
            return NPZDataManager(self.conf, self.log)
        elif ftype == 'hdf5':
            return HDF5DataManager(self.conf, self.log)
        else:
            raise ValueError('Invalid file type in config')

    def write_data(self):
        """
        Writes the data. This is a simple wrapper around the write_data()
        method of the DataManager object, with some code to compute the time it
        took to perform the write operation
        """

        start = time.time()
        self.data.write_data()
        end = time.time()
        self.log.info('Write time: %.2f seconds', end - start)

    def get_height(self):
        """Returns the total height of the device"""
        height = 0
        for layer, ldata in self.conf['Layers'].items():
            layer_t = ldata['params']['thickness']
            height += layer_t
        return height

    def get_scalar_quantity(self, quantity):
        """
        Retrieves the entire 3D matrix for some scalar quantity

        :param str quantity: The quantity you would like to retrive (ex: 'Ex'
                             or 'normE')
        :return: A 3D numpy array shape (zsamples, xsamples, ysamples)
                 containing the specified quantity
        :rtype: np.ndarray
        :raises KeyError: If the specified quantity does not exist in the data
                          dict
        """

        self.log.debug('Retrieving scalar quantity %s', str(quantity))
        try:
            return self.data[quantity]
        except KeyError:
            self.log.error('You attempted to retrieve a quantity that does not'
                           ' exist in the data dict. Attempting to calculate')
        try:
            result = getattr(self, quantity)()
            self.extend_data(quantity, result)
            return self.data[quantity]
        except:
            self.log.error('Unable to calculate following quantity: %s',
                           quantity)
            raise

    def clear_data(self):
        """Clears all the data attributes to free up memory"""
        self.data._update_keys(clear=True)

    def extend_data(self, quantity, new_data):
        """
        Adds a new key, value pair to the DataManager object
        """
        if quantity in self.data:
            self.log.debug("Quantity %s exists in matrix, updating", quantity)
            self.data[quantity] = new_data
        else:
            self.log.debug('Adding %s to data dict', str(quantity))
            self.data[quantity] = new_data

    def get_line(self, quantity, line_dir, c1, c2):
        """
        Gets data along a line through the 3D data array for the given quantity
        along a given direction

        :param str line_dir: Any of 'x', 'y', or 'z'. Determines the direction
                             along which the line cut is taken, the other two
                             coordinates remain fixed and are specified by c1
                             and c2.
        :param int c1: The integer index for the first fixed coordinate.
                       Indexes are in x,y, z order so if line_dir='z' then c1
                       corresponds to x
        :param int c2: The integer index for the second coordinate.
        :param str quantity: The quantity whose data array you wish to take a
                             line cut through
        """

        scalar = self.get_scalar_quantity(quantity)
        if line_dir == 'x':
            # z along rows, y along columns
            return scalar[c2, :, c1]
        elif line_dir == 'y':
            # x along columns, z along rows
            return scalar[c2, c1, :]
        elif line_dir == 'z':
            # x along rows, y along columns
            return scalar[:, c1, c2]

    def get_plane(self, quantity, plane, pval):
        """
        Gets data along a 2D plane/slice through the 3D data array for a given
        quantity

        :param str plane: Any of 'xy', 'yz', or 'xz'. Determines the plane
                          along which the slice is taken
        :param int pval: The index along the final unspecified direction. If
                         plane='xy' then index would index along the z
                         direction.
        :param str quantity: The quantity whose data array you wish to take a
                             line cut through
        """

        self.log.info('Retrieving plane for %s', quantity)
        scalar = self.get_scalar_quantity(quantity)
        if plane == 'yz' or plane == 'zy':
            # z along rows, y along columns
            return scalar[:, pval, :]
        elif plane == 'xz' or plane == 'zx':
            # x along columns, z along rows
            return scalar[:, :, pval]
        elif plane == 'xy' or plane == 'yx':
            # x along rows, y along columns
            return scalar[pval, :, :]

    def normE(self):
        """
        Calculates the norm of E. Adds it to the data dict for the simulation
        and also returns a 3D array
        :return: A 3D numpy array containing :math: |E|
        """

        # Get the magnitude of E and add it to our data
        E_mag = np.zeros_like(self.data['Ex'], dtype=np.float64)
        for comp in ('Ex', 'Ey', 'Ez'):
            E_mag += np.absolute(self.data[comp])**2
        self.extend_data('normE', np.sqrt(E_mag))
        return np.sqrt(E_mag)

    def normEsquared(self):
        """
        Calculates and returns normE squared. Adds it to the data dict for
        the simulation and also returns a 3D array
        :return: A 3D numpy array containing :math: |E|^2
        """

        # Get the magnitude of E and add it to our data
        E_magsq = np.zeros_like(self.data['Ex'], dtype=np.float64)
        for comp in ('Ex', 'Ey', 'Ez'):
            E_magsq += np.absolute(self.data[comp])**2
            # E_magsq += self.data[comp].real**2
        self.extend_data('normEsquared', E_magsq)
        return E_magsq

    def normH(self):
        """Calculate and returns :math: |H|"""

        H_mag = np.zeros_like(self.data['Hx'], dtype=np.float64)
        for comp in ('Hx', 'Hy', 'Hz'):
            H_mag += np.absolute(self.data[comp])
        self.extend_data('normH', H_mag)
        return H_mag

    def normHsquared(self):
        """Calculates and returns :math: |H|^2"""

        H_magsq = np.zeros_like(self.data['Hx'], dtype=np.float64)
        for comp in ('Hx', 'Hy', 'Hz'):
            H_magsq += np.absolute(self.data[comp])**2
        self.extend_data('normHsquared', H_magsq)
        return H_magsq

    def genRate(self):
        """
        Computes and returns the 3D matrix containing the generation rate.
        Returns in units of cm^-3
        """

        # We need to compute normEsquared before we can compute the generation
        # rate
        normEsq = self.get_scalar_quantity('normEsquared')
        # Prefactor for generation rate. Note we gotta convert from m^3 to
        # cm^3, hence 1e6 factor
        fact = c.epsilon_0 / (c.hbar * 1e6)
        gvec = np.zeros_like(normEsq)
        # Main loop to compute generation in each layer
        freq = self.conf[('Simulation', 'params', 'frequency')]
        for name, layer in self.layers.items():
            self.log.debug('LAYER: %s', name)
            self.log.debug('LAYER T: %f', layer.thickness)
            self.log.debug('START: %i', layer.istart)
            self.log.debug('END: %i', layer.iend)
            # Use the layer object to get the nk matrix with correct material
            # geometry
            nmat, kmat = layer.get_nk_matrix(freq)
            gvec[layer.slice] = fact * nmat * kmat * normEsq[layer.slice]
        self.extend_data('genRate', gvec)
        return gvec

    def angularAvg(self, quantity):
        """
        Perform an angular average of some quantity for either the E or H field
        """

        try:
            quant = self.get_scalar_quantity(quantity)
        except KeyError:
            getattr(self, quantity)()
            quant = self.get_scalar_quantity(quantity)
            # Make sure we don't compute it twice
            try:
                self.conf['Postprocessing']['Cruncher'][
                    quantity]['compute'] = False
            except KeyError:
                pass
        # Get spatial discretization
        rsamp = self.conf['Simulation']['r_samples']
        thsamp = self.conf['Simulation']['theta_samples']
        period = self.conf['Simulation']['params']['array_period']
        # Maximum r value such that circle and square unit cell have equal area
        rmax = period / np.sqrt(np.pi)
        # Diff between rmax and unit cell boundary at point of maximum
        # difference
        delta = rmax - period / 2.0
        # Extra indices we need to expand layers by
        x_inds = int(np.ceil(delta / self.dx))
        y_inds = int(np.ceil(delta / self.dy))
        # Use periodic BCs to extend the data in the x-y plane
        ext_vals = np.zeros((quant.shape[0], quant.shape[1] +
                             2 * x_inds, quant.shape[2] + 2 * y_inds),
                            dtype=quant.dtype)
        # Left-Right extensions. This indexing madness extracts the slice we
        # want, flips it along the correct dimension then sticks in the correct
        # spot in the extended array
        ext_vals[:, x_inds:-x_inds, 0:y_inds] = quant[:, :, 0:y_inds][:, :, ::-1]
        ext_vals[:, x_inds:-x_inds, -
                 y_inds:] = quant[:, :, -y_inds:][:, :, ::-1]
        # Top-Bottom extensions
        ext_vals[:, 0:x_inds, y_inds:-
                 y_inds] = quant[:, 0:x_inds, :][:, ::-1, :]
        ext_vals[:, -x_inds:, y_inds:-
                 y_inds] = quant[:, -x_inds:, :][:, ::-1, :]
        # Corners, slightly trickier
        # Top left
        ext_vals[:, 0:x_inds, 0:y_inds] = ext_vals[
            :, x_inds:2 * x_inds, 0:y_inds][:, ::-1, :]
        # Bottom left
        ext_vals[:, -x_inds:, 0:y_inds] = ext_vals[:, -
                                                   2 * x_inds:-x_inds, 0:y_inds][:, ::-1, :]
        # Top right
        ext_vals[:, 0:x_inds, -y_inds:] = ext_vals[:,
                                                   0:x_inds, -2 * y_inds:-y_inds][:, :, ::-1]
        # Bottom right
        ext_vals[:, -x_inds:, -y_inds:] = ext_vals[:, -
                                                   x_inds:, -2 * y_inds:-y_inds][:, :, ::-1]
        # Now the center
        ext_vals[:, x_inds:-x_inds, y_inds:-y_inds] = quant[:, :, :]
        # Extend the points arrays to include these new regions
        x = np.concatenate((np.array([self.dx * i for i in
                                      range(-x_inds, 0)]), self.X,
                            np.array([self.X[-1] + self.dx * i for i in range(1, x_inds + 1)])))
        y = np.concatenate((np.array([self.dy * i for i in
                                      range(-y_inds, 0)]), self.Y,
                            np.array([self.Y[-1] + self.dy * i for i in range(1, y_inds + 1)])))
        # The points on which we have data
        points = (x, y)
        # The points corresponding to "rings" in cylindrical coordinates. Note
        # we construct these rings around the origin so we have to shift them
        # to actually correspond to the center of the nanowire
        rvec = np.linspace(0, rmax, rsamp)
        thvec = np.linspace(0, 2 * np.pi, thsamp)
        cyl_coords = np.zeros((len(rvec) * len(thvec), 2))
        start = 0
        for r in rvec:
            xring = r * np.cos(thvec)
            yring = r * np.sin(thvec)
            cyl_coords[start:start + len(thvec), 0] = xring
            cyl_coords[start:start + len(thvec), 1] = yring
            start += len(thvec)
        cyl_coords += period / 2.0
        # For every z layer in the 3D matrix of our quantity
        avgs = np.zeros((ext_vals.shape[0], len(rvec)))
        i = 0
        for layer in ext_vals:
            interp_vals = interpolate.interpn(
                points, layer, cyl_coords, method='linear')
            rings = interp_vals.reshape((len(rvec), len(thvec)))
            avg = np.average(rings, axis=1)
            avgs[i, :] = avg
            i += 1
        avgs = avgs[:, ::-1]
        # Save to avgs dict for this sim
        key = quantity + '_angularAvg'
        self.data[key] = avgs
        return avgs

    def absorption_per_layer(self, per_area=True):
        """
        Computes the absorption in each layer of the device using two methods.
        The first method takes the difference between the areal power fluxes
        entering a layer and leaving a layer.

        :math:`P_{abs} = P_{in} - P_{out}`

        The second method uses the raw fields and computes a volume integral of
        the norm squared of the electric field

        .. math::

           P_{abs} &= \\frac{\\omega}{2} \\int |E|^2
                      \\mathrm{Im}[\\epsilon] dV \\\\
                   &= \\frac{\\omega \\epsilon_0}{2}
                      \\int |E|^2 \\mathrm{Im}[\\epsilon_r] dV

        Recall :math:`\mathrm{Im}[\epsilon_r] = 2nk` so we finally arrive at

        .. math::

           P_{abs} = \omega \int |E|^2 n k dV

        This provides a metric for quantifying how converged the real space
        reconstructions of the fields are.

        :param per_area: Compute the absorption in units of power per unit area
                         or not. If True, in units of Watts/micrometer^2
        :type per_area: bool
        """

        fluxes = self.data['fluxes']
        base_unit = self.conf['Simulation']['base_unit']
        Zo = consts.physical_constants['characteristic impedance of vacuum'][0]
        try:
            Esq = self.data['normEsquared']
        except KeyError:
            Esq = self.normEsquared()
        freq = self.conf[('Simulation', 'params', 'frequency')]
        dt = [('layer', 'S25'), ('flux_method', 'c16'), ('int_method', 'c16'),
              ('difference', 'f8')]
        num_rows = len(list(self.layers.keys()))
        absorb_arr = np.recarray((num_rows,), dtype=dt)
        counter = 0
        for layer_name, layer_obj in self.layers.items():
            # Method 1: Go through power flux
            blayer_name = layer_name.encode('utf-8')
            bottom = layer_name+'_bottom'
            bbottom = bottom.encode('utf-8')
            port, forw_top, back_top = fluxes[fluxes.layer == blayer_name][0]
            port, forw_bot, back_bot = fluxes[fluxes.layer == bbottom][0]
            # Minus sign because S4 stick a minus in front of all backward
            # components
            Pin = forw_top - back_bot
            Pout = forw_bot - back_top
            Plost = Pin - Pout
            # S4 returns \int |E|^2 / Area, so we need to multiply by the area
            # here. Factor of one over vacuum impedance to get the units into
            # power.
            Pabs_flux = .5*Plost/Zo
            if not per_area:
                Pabs_flux *= self.period**2
            self.log.info("Layer: {}".format(layer_name))
            self.log.info("Flux Method Absorbed: {}".format(Pabs_flux))
            # Method 2: Go through integral of field intensity
            # if layer_name == 'Air':
            #     continue
            n_mat, k_mat = layer_obj.get_nk_matrix(freq)
            # n and k could be functions of space, so we need to multiply the
            # fields by n and k before integrating
            arr_slice = Esq[layer_obj.slice]*n_mat*k_mat
            z_vals = self.Z[layer_obj.istart:layer_obj.iend]
            z_integral = intg.trapz(arr_slice, x=z_vals, axis=0)
            x_integral = intg.trapz(z_integral, x=self.X, axis=0)
            y_integral = intg.trapz(x_integral, x=self.Y, axis=0)
            # print('Arr slice shape: {}'.format(arr_slice.shape))
            # x_integral = intg.trapz(arr_slice, x=self.X, axis=1)
            # print('X Integral shape: {}'.format(x_integral.shape))
            # y_integral = intg.trapz(x_integral, x=self.Y, axis=1)
            # print('Y Integral shape: {}'.format(y_integral.shape))
            # z_integral = intg.trapz(y_integral, x=z_vals, axis=0)
            # 2\pi for conversion to angular frequency
            # epsilon_0 comes out of dielectric constant
            # Factor of base unit because we need to convert from our reference
            # lengths in base units to SI reference length unit (meters)
            # Factor of 1/2 for time averaging gets canceled by imaginary part
            # of dielectric constant (2*n*k)
            Pabs_integ = 2*np.pi*freq*c.epsilon_0*base_unit*y_integral
            # Pabs_integ = 2*np.pi*freq*c.epsilon_0*base_unit*z_integral
            if per_area:
                Pabs_integ /= self.period**2
            self.log.info("Integrated Absorbed: {}".format(Pabs_integ))
            diff = np.abs(Pabs_flux - Pabs_integ)
            absorb_arr[counter] = (layer_name, Pabs_flux, Pabs_integ, diff)
            counter += 1
        self.log.info("Layer absorption arr: %s", str(absorb_arr))
        self.data['abs_per_layer'] = absorb_arr
        return absorb_arr

    def transmissionData(self, port='Substrate_bottom'):
        """
        Computes reflection, transmission, and absorbance

        :param str port: Name of the location at which you would like to place
                         the transmission port (i.e where you would like to
                         compute transmission). This must correspond to one of
                         the keys placed in the fluxes dict located at
                         self.data['fluxes']
        """

        data = self.data['fluxes']
        # sorted_layers is an OrderedDict, and thus has the popitem method
        sorted_layers = self.conf.sorted_dict(self.conf['Layers'])
        # self.log.info('SORTED LAYERS: %s', str(sorted_layers))
        first_layer = sorted_layers.popitem(last=False)
        self.log.info('FIRST LAYER: %s', str(first_layer))
        # An ordered dict is actually just a list of tuples so we can access
        # the key directly like so
        first_name = first_layer[0]
        bfirst_name = first_name.encode('utf-8')
        self.log.info('FIRST LAYER NAME: %s', str(first_name))
        bport = port.encode('utf-8')
        # p_inc = data[first_name][0]
        # p_ref = np.abs(data[first_name][1])
        # p_trans = data[last_name][0]
        p_inc = np.absolute(data[data.layer == bfirst_name][0][1])
        p_ref = np.absolute(data[data.layer == bfirst_name][0][2])
        p_trans = np.absolute(data[data.layer == bport][0][1])
        reflectance = p_ref / p_inc
        transmission = p_trans / p_inc
        absorbance = 1 - reflectance - transmission
        tot = reflectance + transmission + absorbance
        delta = np.abs(tot - 1)
        self.log.info('Reflectance %f' % reflectance)
        self.log.info('Transmission %f' % transmission)
        self.log.info('Absorbance %f' % absorbance)
        self.log.info('Total = %f' % tot)
        assert(reflectance >= 0)
        assert(transmission >= 0)
        assert(absorbance >= 0)
        # assert(delta < .00001)
        # Try to get a prexisting array if it exists
        try:
            # If array has been computed before get it
            arr = self.data['transmission_data']
            # If we already have data at this port update that row, otherwise
            # resize the array to accomodate the new row and insert the data
            ind = np.where(arr.port == port.encode('utf-8'))[0]
            if len(ind) > 0:
                arr[ind[0]] = (port, reflectance, transmission, absorbance)
            else:
                arr = np.resize(arr, arr.shape[0]+1)
                arr[-1] = (port, reflectance, transmission, absorbance)
        except:
            # Otherwise we need to make a new one
            dt = [('port', 'S25'), ('reflection', 'f8'),
                  ('transmission', 'f8'), ('absorption', 'f8')]
            arr = np.recarray((1,), dtype=dt)
            arr[-1] = (port, reflectance, transmission, absorbance)
        self.data['transmission_data'] = arr
        return reflectance, transmission, absorbance

    def get_incident_power(self):
        """
        Returns the incident power for this simulation depending on frequency

        Each simulation is conducted at a single frequency :math:`f =  \\omega
        / 2\\pi` which is associated with a frequency "bin" of spectral width
        :math:`\\Delta f`. The solar spectrum is expressed in units of Watts *
        m^-2 * Hz^-1. In order to compute the incident power for this
        simulation, we have a few options

        1. Interpolate to find the spectral irradiance at the frequency for
           this simulation, then multiply by the spectral width
        2. Find all available irradiance values contained inside the frequency
           bin, then integrate over the bin using those values as data points.
           The bin extends from :math:`(f - \\Delta f/2, f + \\Delta f/2)`, so
           in summary

           .. math:: \\int_{f - \\Delta f/2}^{f + \\Delta f/2} I(f) df

           where :math:`I` is the incident solar irradiance.

        Method 2 is used in this function, because it is debatably more
        accurate.

        :raises ValueError: If the maximum or minimum bin edge extend beyond
                            the data range in the provided spectral data
        """


        freq = self.conf['Simulation']['params']['frequency']['value']
        polar_angle = self.conf['Simulation']['params']['polar_angle']['value']
        path = os.path.expandvars(self.conf['Simulation']['input_power'])
        bin_size = self.conf['Simulation']['params']['frequency']['bin_size']
        # Get NREL AM1.5 data
        freq_vec, p_vec = np.loadtxt(path, unpack=True, delimiter=',')
        # Get all available power values within this bin
        left = freq - bin_size / 2.0
        right = freq + bin_size / 2.0
        inds = np.where((left < freq_vec) & (freq_vec < right))[0]
        # Check for edge cases
        if len(inds) == 0:
            # It is unphysical to claim that an input wave of a single
            # frequency can contain any power. If we're simulating at a single
            # frequency, just assume the wave has the power contained within
            # the NREL bin surrounding that frequency
            self.log.warning('Your bins are smaller than NRELs! Using NREL'
                             ' bin size')
            closest_ind = np.argmin(np.abs(freq_vec - freq))
            # Is the closest one to the left or the right?
            if freq_vec[closest_ind] > freq:
                other_ind = closest_ind - 1
                left = freq_vec[other_ind]
                left_power = p_vec[other_ind]
                right = freq_vec[closest_ind]
                right_power = p_vec[closest_ind]
            else:
                other_ind = closest_ind + 1
                right = freq_vec[other_ind]
                right_power = p_vec[other_ind]
                left = freq_vec[closest_ind]
                left_power = p_vec[closest_ind]
        elif inds[0] == 0:
            raise ValueError('Your leftmost bin edge lies outside the'
                             ' range provided by NREL')
        elif inds[-1] == len(freq_vec):
            raise ValueError('Your rightmost bin edge lies outside the'
                             ' range provided by NREL')
        else:
            # A simple linear interpolation given two pairs of data points, and the
            # desired x point
            def lin_interp(x1, x2, y1, y2, x):
                return ((y2 - y1) / (x2 - x1)) * (x - x2) + y2
            # If the left or right edge lies between NREL data points, we do a
            # linear interpolation to get the irradiance values at the bin edges.
            # If the left of right edge happens to be directly on an NREL bin edge
            # (unlikely) the linear interpolation will just return the value at the
            # NREL bin. Also the selection of inds above excluded the case of left
            # or right being equal to an NREL bin,
            left_power = lin_interp(freq_vec[inds[0] - 1], freq_vec[inds[0]],
                                    p_vec[inds[0] - 1], p_vec[inds[0]], left)
            right_power = lin_interp(freq_vec[inds[-1]], freq_vec[inds[-1] + 1],
                                     p_vec[inds[-1]], p_vec[inds[-1] + 1], right)
        # All the frequency values within the bin and including the bin edges
        freqs = [left]+list(freq_vec[inds])+[right]
        # All the power values
        power_values = [left_power]+list(p_vec[inds])+[right_power]
        self.log.info(freqs)
        self.log.info(power_values)
        # Just use a trapezoidal method to integrate the spectrum
        power = intg.trapz(power_values, x=freqs)
        self.log.info('Incident Power: %s', str(power))
        return power

    def integrate_quantity(self, q, mask=None, layer=None):
        """
        Compute a 3D integral of a specified quantity

        :param q: A key in the self.data dict that specifies the quantity you
                  wish to integrate
        :type q: str
        :param mask: A numpy array of ones and zeros, which can be 2D or 3D. If
                     a 3D array is provided, it will multiply the 3D array of
                     the quantity elementwise before integration. The
                     z-direction is along the first axis, i.e mask[z, x, y].
                     If a 2D array is provided, it will be extended along the
                     z-direction and then will multiply the 3D array of the
                     quantity elementwise before integration. This can be
                     useful if you want to integrate only over a specific
                     region of the device. You would supply a 3D mask that is
                     1 inside that region, and zero outside that region.
                     Combining with the layer arg is supported.
        :type mask: np.ndarray
        :param layer: The name of the layer you wish to integrate over.
                      Providing this will extract a 3D slice of data that is in
                      the specified layer, and only integrate over that slice.
                      Use this if you do not want to include all layers in the
                      integration. Combining with the mask arg is supported.
        :type layer: str
        :return: Result of :math:`\\int quantity(x, y, z) dV`
        :rtype: float
        """
        qarr = self.get_scalar_quantity(q)
        if layer is not None:
            l = self.layers[layer]
            z_vals = self.Z[layer.istart, layer.iend]
            qarr = qarr[l.slice]
            if mask is not None and len(mask.shape) == 3:
                mask = mask[l.slice]
        else:
            z_vals = self.Z
        if mask is not None:
            qarr = qarr*mask
        z_integral = intg.trapz(qarr, x=z_vals, axis=0)
        x_integral = intg.trapz(z_integral, x=self.X, axis=0)
        y_integral = intg.trapz(x_integral, x=self.Y, axis=0)
        return y_integral

    def jsc_contrib(self, port='Substrate_bottom'):
        self.log.info('Computing Jsc contrib')
        wv_fact = c.e / (c.c * c.h * 10)
        # Unpack data for the port we passed in as an argument
        try:
            arr = self.data['transmission_data']
            port, ref, trans, absorb = arr[arr.port == port.encode('utf-8')][0]
        except KeyError:
            ref, trans, absorb = self.transmissionData(port=port)
        freq = self.conf['Simulation']['params']['frequency']
        wvlgth = c.c / freq
        wvlgth_nm = wvlgth * 1e9
        # Get solar power from chosen spectrum
        sun_pow = self._get_incident_amplitude()
        # This is our integrand
        val = absorb * wvlgth * sun_pow
        # val = absorb * wvlgth
        # test = absorb * sun_pow * wvlgth_nm * wv_fact * delta_wv
        # self.log.info('Sim %s Jsc Integrand: %f', self.id, test)
        # Use Trapezoid rule to perform the integration. Note all the
        # necessary factors of the wavelength have already been included
        # above
        Jsc = wv_fact * val
        outf = os.path.join(self.dir, 'jsc_contrib.dat')
        with open(outf, 'w') as out:
            out.write('%f\n' % Jsc)
        self.log.info('Jsc contrib = %f', Jsc)
        return Jsc

    def jsc_integrated_contrib(self):
        self.log.info('Computing integrated Jsc contribution')
        try:
            genRate = self.data['genRate']
        except KeyError:
            genRate = self.genRate()
        # Gen rate in cm^-3. Gotta convert lengths here from um to cm
        z_integral = intg.trapz(genRate, x=self.Z, axis=0)
        x_integral = intg.trapz(z_integral, x=self.X, axis=0)
        y_integral = intg.trapz(x_integral, x=self.Y, axis=0)
        # Convert period to cm and current to mA
        sun_pow = self._get_incident_amplitude()
        self.log.info('Sun power = %f', sun_pow)
        self.log.info('Integral = %f', y_integral)
        Jsc = 1000*(c.e/(self.period*1e-4)**2)*y_integral
        outf = os.path.join(self.dir, 'jsc_integrated_contrib.dat')
        with open(outf, 'w') as out:
            out.write('%f\n' % Jsc)
        self.log.info('Jsc_integrated contrib = %f', Jsc)
        return Jsc

    def integrated_absorbtion(self):
        """
        Computes the absorption of a layer by using the volume integral of
        the product of the imaginary part of the relative permittivity and the
        norm squared of the E field
        """

        raise NotImplementedError('There are some bugs in S4 and other reasons'
                                  ' that this function doesnt work yet')
        base = self.conf['General']['sim_dir']
        path = os.path.join(base, 'integrated_absorption.dat')
        inpath = os.path.join(base, 'energy_densities.dat')
        freq = self.conf['Simulation']['params']['frequency']
        # TODO: Assuming incident amplitude and therefore incident power is
        # just 1 for now
        fact = -.5 * freq * c.epsilon_0
        with open(inpath, 'r') as inf:
            lines = inf.readlines()
            # Remove header line
            lines.pop(0)
            # Dict where key is layer name and value is list of length 2 containing real and
            # imaginary parts of energy density integral
            data = {line.strip().split(',')[0]: line.strip().split(',')[
                1:] for line in lines}
        self.log.info('Energy densities: %s' % str(data))
        with open(path, 'w') as outf:
            outf.write('# Layer, Absorption\n')
            for layer, vals in data.items():
                absorb = fact * float(vals[1])
                outf.write('%s,%s\n' % (layer, absorb))

    def _draw_layer_circle(self, ldata, shape_key, start, end, plane, pval, ax_hand):
        """Draws the circle within a layer"""
        shape_data = ldata['geometry'][shape_key]
        center = shape_data['center']
        radius = shape_data['radius']
        if plane == 'xy':
            circle = mpatches.Circle((center['x'], center['y']), radius=radius,
                                     fill=False)
            ax_hand.add_artist(circle)
        if plane in ["xz", "zx", "yz", "zy"]:
            plane_x = pval*self.dx
            plane_to_center = np.abs(center['x'] - plane_x)
            self.log.debug('DIST: {}'.format(plane_to_center))
            # Only draw if the observation plane actually intersects with the
            # circle
            if not plane_to_center >= radius:
                # Check if the plane intersects with the center of the circle
                if plane_to_center > 0:
                    intersect_angle = np.arccos(plane_to_center/radius)
                    self.log.debug('ANGLE: {}'.format(intersect_angle))
                    half_width = plane_to_center*np.tan(intersect_angle)
                else:
                    half_width = radius
                self.log.debug('HALF WIDTH: {}'.format(half_width))
                # Vertical lines should span height of the layer
                z = [self.height - start * self.dz, self.height - end * self.dz]
                # The upper edge
                x = [center['y'] + half_width, center['y'] + half_width]
                line = mlines.Line2D(x, z, linestyle='solid', linewidth=2.0,
                                     color='grey')
                ax_hand.add_line(line)
                # Now the lower edge
                x = [center['y'] - half_width, center['y'] - half_width]
                line = mlines.Line2D(x, z, linestyle='solid', linewidth=2.0,
                                     color='grey')
                ax_hand.add_line(line)
        return ax_hand

    def _draw_layer_geometry(self, ldata, start, end, plane, pval, ax_hand):
        """Given a dictionary with the data containing the geometry for a
        layer, draw the internal geometry of the layer for a given plane type
        and plane value"""
        for shape, data in ldata['geometry'].items():
            if data['type'] == 'circle':
                ax = self._draw_layer_circle(ldata, shape, start, end,
                                             plane, pval, ax_hand)
            else:
                self.log.warning('Drawing of shape {} not '
                                 'supported'.format(data['type']))
        return ax

    def draw_geometry_2d(self, plane, pval, ax_hand, skip_list=[]):
        """This function draws the layer boundaries and in-plane geometry on 2D
        heatmaps"""
        # Get the layers in order
        ordered_layers = self.conf.sorted_dict(self.conf['Layers'])
        period = self.conf['Simulation']['params']['array_period']
        # Loop through them
        boundaries = []
        count = 0
        for layer, ldata in ordered_layers.items():
            # If x or y, draw bottom edge and text label now. Layer geometry
            # is handled in its own function
            if plane in ["xz", "zx", "yz", "zy"]:
                # Get boundaries between layers and their starting and ending
                # indices
                layer_t = ldata['params']['thickness']
                if count == 0:
                    start = 0
                    end = int(layer_t / self.dz) + 1
                    boundaries.append((layer_t, start, end, layer))
                else:
                    prev_tup = boundaries[count - 1]
                    dist = prev_tup[0] + layer_t
                    start = prev_tup[2]
                    end = int(dist / self.dz) + 1
                    boundaries.append((dist, start, end))
                if layer_t > 0:
                    if layer not in skip_list:
                        x = [0, period]
                        y = [self.height - start * self.dz,
                             self.height - start * self.dz]
                        label_y = y[0] + 3*self.dz
                        label_x = x[-1] - .01
                        # ax_hand.text(label_x, label_y, layer, ha='right',
                        #              family='sans-serif', size=16, color='grey')
                        line = mlines.Line2D(x, y, linestyle='solid', linewidth=2.0,
                                             color='grey')
                        ax_hand.add_line(line)
                    count += 1
            else:
                # If look at a fixed z pval, the start and end values are
                # nonsensical but we must pass a value in
                start, end = None, None
            # If we have some internal geometry for this layer, draw it
            if 'geometry' in ldata:
                ax_hand = self._draw_layer_geometry(ldata, start, end, plane, pval, ax_hand)
        return ax_hand

    def heatmap2d(self, x, y, cs, labels, ptype, pval, save_path=None,
                  show=False, draw=False, fixed=None, colorsMap='jet'):
        """A general utility method for plotting a 2D heat map"""
        cm = plt.get_cmap(colorsMap)
        if np.iscomplexobj(cs):
            self.log.warning('Plotting only real part of %s in heatmap',
                             labels[2])
            cs = cs.real
        if fixed:
            if 'dielectric_profile' in save_path:
                cNorm = matplotlib.colors.Normalize(
                    vmin=np.amin(0), vmax=np.amax(16))
            else:
                pass
                cNorm = matplotlib.colors.Normalize(
                    vmin=np.amin(cs), vmax=np.amax(cs))
                # cNorm = matplotlib.colors.Normalize(
                #     vmin=np.amin(0), vmax=np.amax(2.5))
        else:
            cNorm = matplotlib.colors.Normalize(
                vmin=np.amin(cs), vmax=np.amax(cs))
            # cNorm = matplotlib.colors.LogNorm(vmin=np.amin(cs)+.001, vmax=np.amax(cs))
            # cNorm = matplotlib.colors.LogNorm(vmin=1e13, vmax=np.amax(cs))
        scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=cm)
        fig = plt.figure(figsize=(10, 8))
        ax = fig.add_subplot(111)
        ax.imshow(cs,cmap=cm,norm=cNorm,extent=[x.min(),x.max(),y.min(),y.max()],aspect='auto')
        ax.grid(False)
        scalarMap.set_array(cs)
        # div = make_axes_locatable(ax)
        # zoom_ax = div.append_axes("right",size='100%', pad=.5)
        # zoom_ax.imshow(cs[75:100,:], extent=[x.min(), x.max(), .8, 1.4])
        # zoom_ax.grid(False)
        # cax = div.append_axes("right",size="100%",pad=.05)
        cb = fig.colorbar(scalarMap)
        cb.set_label(labels[2])
        ax.set_xlabel(labels[0])
        ax.set_ylabel(labels[1])
        if draw:
            self.log.info('Beginning geometry drawing routines ...')
            ax = self.draw_geometry_2d(ptype, pval, ax)
        if save_path:
            fig.savefig(save_path, bbox_inches='tight')
        if show:
            plt.show()
        plt.close(fig)

    def plane_2d(self, quantity, plane, pval, draw=False, fixed=None):
        """Plots a heatmap of a fixed 2D plane"""
        self.log.info('Plotting plane')
        pval = int(pval)
        x = np.arange(0, self.period, self.dx)
        y = np.arange(0, self.period, self.dy)
        z = np.arange(0, self.height + self.dz, self.dz)
        # Get the scalar values
        freq = self.conf['Simulation']['params']['frequency']
        wvlgth = (c.c / freq) * 1E9
        title = 'Frequency = {:.4E} Hz, Wavelength = {:.2f} nm'.format(
            freq, wvlgth)
        # Get the plane we wish to plot
        cs = self.get_plane(quantity, plane, pval)
        self.log.info('DATA SHAPE: %s' % str(cs.shape))
        show = self.conf['General']['show_plots']
        p = False
        sim_dir = os.path.expandvars(self.conf['General']['sim_dir'])
        if plane == 'yz' or plane == 'zy':
            labels = ('y [um]', 'z [um]', quantity, title)
            if self.conf['General']['save_plots']:
                p = os.path.join(sim_dir,
                                 '%s_plane_2d_yz_pval%s.pdf' % (quantity,
                                                               str(pval)))
            self.heatmap2d(y, z, cs, labels, plane, pval,
                           save_path=p, show=show, draw=draw, fixed=fixed)
        elif plane == 'xz' or plane == 'zx':
            labels = ('x [um]', 'z [um]', quantity, title)
            if self.conf['General']['save_plots']:
                p = os.path.join(sim_dir,
                                 '%s_plane_2d_xz_pval%s.pdf' % (quantity,
                                                               str(pval)))
            self.heatmap2d(x, z, cs, labels, plane, pval,
                           save_path=p, show=show, draw=draw, fixed=fixed)
        elif plane == 'xy' or plane == 'yx':
            labels = ('y [um]', 'x [um]', quantity, title)
            if self.conf['General']['save_plots']:
                p = os.path.join(sim_dir,
                                 '%s_plane_2d_xy_pval%s.pdf' % (quantity,
                                                               str(pval)))
            self.heatmap2d(x, y, cs, labels, plane, pval,
                           save_path=p, show=show, draw=draw, fixed=fixed)

    def scatter3d(self, x, y, z, cs, labels, ptype, colorsMap='jet'):
        """A general utility method for scatter plots in 3D"""
        cm = plt.get_cmap(colorsMap)
        cNorm = matplotlib.colors.Normalize(vmin=min(cs), vmax=max(cs))
        scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=cm)
        fig = plt.figure(figsize=(9, 7))

        ax = fig.add_subplot(111, projection='3d')
        ax.scatter(x, y, z, c=scalarMap.to_rgba(cs), edgecolor='none')
        scalarMap.set_array(cs)
        cb = fig.colorbar(scalarMap)
        cb.set_label(labels[3])
        ax.set_xlabel(labels[0])
        ax.set_ylabel(labels[1])
        ax.set_zlabel(labels[2])
        fig.suptitle(os.path.basename(self.conf['General']['sim_dir']))
        if self.conf['General']['save_plots']:
            name = labels[-1] + '_' + ptype + '.pdf'
            path = os.path.join(self.conf['General']['sim_dir'], name)
            fig.savefig(path)
        if self.conf['General']['show_plots']:
            plt.show()
        plt.close(fig)

    def full_3d(self, quantity):
        """Generates a full 3D plot of a specified scalar quantity"""
        # The data just tells you what integer grid point you are on. Not what actual x,y coordinate you
        # are at
        x = np.arange(0, self.period, self.dx)
        y = np.arange(0, self.period, self.dy)
        z = np.arange(0, self.height + self.dz, self.dz)
        points = np.array(list(itertools.product(z, x, y)))
        # Get the scalar
        scalar = self.get_scalar_quantity(quantity)
        labels = ('X [um]', 'Y [um]', 'Z [um]', quantity)
        # Now plot!
        self.scatter3d(points[:, 1], points[:, 2], points[
                       :, 0], scalar.flatten(), labels, 'full_3d')

    def planes_3d(self, quantity, xplane, yplane):
        """Plots some scalar quantity in 3D but only along specified x-z and y-z planes"""
        xplane = int(xplane)
        yplane = int(yplane)
        # Get the scalar values
        # Get the data on the plane with a fixed x value. These means we'll
        # have changing (y, z) points
        xdata = self.get_plane(quantity, 'yz', xplane)
        # z first cuz we want y to be changing before z to correspond with the
        # way numpy flattens arrays. Note this means y points will be in the
        # 2nd column
        xplanepoints = np.array(list(itertools.product(self.Z, self.Y)))
        xdata = xdata.flatten()
        xplanexval = np.array(list(itertools.repeat(x[xplane], len(xdata))))
        xplanedata = np.zeros((xplanepoints.shape[0], 4))
        xplanedata[:, 0] = xplanexval
        xplanedata[:, 1] = xplanepoints[:, 1]
        xplanedata[:, 2] = xplanepoints[:, 0]
        xplanedata[:, 3] = xdata
        # Same procedure for fixed y plane
        ydata = self.get_plane(quantity, 'xz', yplane)
        yplanepoints = np.array(list(itertools.product(z, x)))
        ydata = ydata.flatten()
        yplaneyval = np.array(list(itertools.repeat(y[yplane], len(ydata))))
        yplanedata = np.zeros((yplanepoints.shape[0], 4))
        yplanedata[:, 0] = yplanepoints[:, 1]
        yplanedata[:, 1] = yplaneyval
        yplanedata[:, 2] = yplanepoints[:, 0]
        yplanedata[:, 3] = ydata
        labels = ('X [um]', 'Y [um]', 'Z [um]', quantity)
        # Now stack them vertically and plot!
        all_data = np.vstack((xplanedata, yplanedata))
        self.scatter3d(all_data[:, 0], all_data[:, 1], all_data[:, 2],
                       all_data[:, 3], labels, 'planes_3d')

    def line_plot(self, x, y, labels, ax=None):
        """Make a simple line plot and return the figure and axes handles"""
        if ax is None:
            fig, ax = plt.subplots()
        else:
            fig = None
        ax.plot(x, y, label=labels[0])
        ax.set_xlabel(labels[1])
        ax.set_ylabel(labels[2])
        ax.set_title(labels[3])
        return fig, ax

    def fixed_line(self, quantity, direction, coord1, coord2):
        """
        Plot a scalar quantity on a line along a given direction at some pair
        of coordinates in the plane perpendicular to that direction. The
        remaining coordinates are specified in x, y, z order. So for example if
        direction='z' then coord1 corresponds to x and coord2 corresponds to y.
        If direction='y' then coord1 corresponds to x and coord2 corresponds to
        z.
        :param str direction: The direction along which to plot the line. Must
        be one of 'x', 'y', or 'z'.
        :param str direction: The direction along which you wish to plot a
        line. Must be one of 'x', 'y', or 'z'. The other two coordinates remain
        fixed and are specified by coord1 and coord2.
        :param int coord1: The integer index for the first fixed coordinate.
        Indexes are in x,y, z order so if line_dir='z' then c1 corresponds to x
        :param int coord2: The integer index for the second coordinate.
        :param str quantity: The quantity whose data array you wish to take a
        line cut through
        """

        coord1 = int(coord1)
        coord2 = int(coord2)
        # Get the scalar values
        # Filter out any undesired data that isn't on the planes
        data = self.get_line(quantity, direction, coord1, coord2)
        if direction == 'x':
            # z along rows, y along columns
            pos_data = self.X
        elif direction == 'y':
            # x along columns, z along rows
            pos_data = self.Y
        elif direction == 'z':
            # x along rows, y along columns
            pos_data = self.Z
        freq = self.conf['Simulation']['params']['frequency']
        wvlgth = (c.c / freq) * 1E9
        title = 'Frequency = {:.4E} Hz, Wavelength = {:.2f} nm'.format(
            freq, wvlgth)
        ptype = "%s_line_plot_%i_%i" % (direction, coord1, coord2)
        if np.iscomplexobj(data):
            labels = ('Real Part', 'Z [um]', quantity, title)
            fig, ax = self.line_plot(pos_data, data.real, labels)
            labels = ('Imag Part', 'Z [um]', quantity, title)
            _, ax = self.line_plot(pos_data, data.imag, labels, ax=ax)
        else:
            labels = (None, 'Z [um]', quantity, title)
            fig, ax = self.line_plot(pos_data, data, labels)
        ax.legend()
        if self.conf['General']['save_plots']:
            name = labels[2] + '_' + ptype + '.pdf'
            sim_dir = os.path.expandvars(self.conf['General']['sim_dir'])
            path = os.path.join(sim_dir, name)
            fig.savefig(path)
        if self.conf['General']['show_plots']:
            plt.show()

class SimulationGroup:

    """
    A group of simulations. Takes a list of Simulation objects as an argument.
    This class is not responsible for grouping Simulation objects by some
    criteria, it just expects a list of already grouped Simulation objects.

    Provides methods for calculating things on a group of simulations. The
    results of these methods might not be sensible for some groupings. For
    example, calculating the convergence of a group that is group against
    frequency doesn't make any sense. Similiarly, calculating Jsc of a group
    that is grouped against number of basis terms also doesn't make sense.
    """

    def __init__(self, sims):
        self.sims = sims
        # for sim in self.sims:
        #     sim.get_layers()
        self.log = logging.getLogger(__name__)
        self.num_sims = len(sims)


    def get_plane(self, scalar, plane, pval):
        """
        Gets data along a 2D plane/slice through the 3D data array for a given
        quantity

        :param str plane: Any of 'xy', 'yz', or 'xz'. Determines the plane
        along which the slice is taken
        :param int pval: The index along the final unspecified direction. If
        plane='xy' then index would index along the z direction.
        :param str quantity: The quantity whose data array you wish to take a
        line cut through
        """

        if plane == 'yz' or plane == 'zy':
            # z along rows, y along columns
            return scalar[:, pval, :]
        elif plane == 'xz' or plane == 'zx':
            # x along columns, z along rows
            return scalar[:, :, pval]
        elif plane == 'xy' or plane == 'yx':
            # x along rows, y along columns
            return scalar[pval, :, :]

    def diff_sq(self, x, y):
        """Returns the magnitude of the difference vector squared between two vector fields at each
        point in space"""
        # Calculate the magnitude of the difference vector SQUARED at each point in space
        # This is mag(vec(x) - vec(y))^2 at each point in space. This should be a 1D array
        # with # of elements = # sampling points
        mag_diff_vec = sum([np.absolute(v1 - v2)**2 for v1, v2 in zip(x, y)])
        return mag_diff_vec

    def get_slice(self, sim):
        """Returns indices for data that strip out air and substrate regions"""
        # TODO: This function is definitely not general. We need to get a list
        # of layers to exclude from the user. For now, just assume we want to
        # exclude the top and bottom regions
        # sorted_layers is an OrderedDict, and thus has the popitem method
        sorted_layers = sim.conf.sorted_dict(sim.conf['Layers'])
        first_layer = sorted_layers.popitem(last=False)
        last_layer = sorted_layers.popitem()
        # We can get the starting and ending planes from their heights
        start_plane = int(round(first_layer[1]['params'][
                          'thickness'] / sim.dz))
        end_plane = int(round(last_layer[1]['params'][
                        'thickness'] / sim.dz))
        return start_plane, end_plane

    def get_comp_vec(self, sim, field, start, end):
        """Returns the comparison vector"""
        # Compare all other sims to our best estimate, which is sim with highest number of
        # basis terms (last in list cuz sorting)

        # Get the proper file extension depending on the field.
        norm = 'norm'+field
        # Get the comparison vector
        vecs = [sim.data[field+comp][start:end] for comp in ('x', 'y', 'z')]
        normvec = sim.get_scalar_quantity('normE')
        normvec = normvec[start:end]**2
        return vecs, normvec

    def local_error(self, field, exclude=False):
        """Computes the average of the local error between the vector fields of two simulations at
        each point in space"""
        self.log.info('Running the local error computation for quantity %s', field)
        # If we need to exclude calculate the indices
        if exclude:
            start, end = self.get_slice(self.sims[0])
            excluded = '_excluded'
        else:
            start = 0
            end = None
            excluded = ''
        base = self.sims[0].conf['General']['results_dir']
        errpath = os.path.join(base, 'localerror_%s%s.dat' % (field, excluded))
        with open(errpath, 'w') as errfile:
            self.log.info('Computing local error for sweep %s', base)
            # Set the reference sim
            ref_sim = self.sims[-1]
            # Get the comparison vector
            vecs1, normvec = self.get_comp_vec(ref_sim, field, start, end)
            # For all other sims in the groups, compare to best estimate
            # and write to error file
            for i in range(0, self.num_sims - 1):
                sim2 = self.sims[i]
                vecs2, normvec2 = self.get_comp_vec(sim2, field, start, end)
                self.log.info("Computing local error between numbasis %i and numbasis %i",
                              ref_sim.conf['Simulation'][ 'params']['numbasis'],
                              sim2.conf['Simulation']['params']['numbasis'])
                # Get the array containing the magnitude of the difference vector at each point
                # in space
                mag_diff_vec = self.diff_sq(vecs1, vecs2)
                # Normalize the magnitude squared of the difference vector by the magnitude squared of
                # the local electric field of the comparison simulation at
                # each point in space
                if len(mag_diff_vec) != len(normvec):
                    self.log.error("The normalization vector has an incorrect number of elements!!!")
                    raise ValueError
                norm_mag_diff = mag_diff_vec / normvec
                # Compute the average of the normalized magnitude of all
                # the difference vectors
                avg_diffvec_mag = np.sum(norm_mag_diff) / norm_mag_diff.size
                errfile.write('%i,%f\n' % (sim2.conf['Simulation']['params']['numbasis'],
                                           avg_diffvec_mag))
                sim2.clear_data()
            ref_sim.clear_data()

    def global_error(self, field, exclude=False):
        """Computes the global error between the vector fields of two simulations. This is the sum
        of the magnitude squared of the difference vectors divided by the sum of the magnitude
        squared of the comparison efield vector over the desired section of the simulation cell"""

        self.log.info('Running the global error computation for quantity %s', field)
        # If we need to exclude calculate the indices
        if exclude:
            start, end = self.get_slice(self.sims[0])
            excluded = '_excluded'
        else:
            start = 0
            end = None
            excluded = ''
        # base = self.sims[0].conf['General']['base_dir']
        base = self.sims[0].conf['General']['results_dir']
        errpath = os.path.join(base, 'globalerror_%s%s.dat' % (field, excluded))
        with open(errpath, 'w') as errfile:
            self.log.info('Computing global error for sweep %s', base)
            # Set reference sim
            ref_sim = self.sims[-1]
            # Get the comparison vector
            vecs1, normvec = self.get_comp_vec(ref_sim, field, start, end)
            # For all other sims in the groups, compare to best estimate
            # and write to error file
            for i in range(0, self.num_sims - 1):
                sim2 = self.sims[i]
                vecs2, normvec2 = self.get_comp_vec(sim2, field, start, end)
                self.log.info("Computing global error between numbasis %i and numbasis %i",
                              ref_sim.conf['Simulation'][ 'params']['numbasis'],
                              sim2.conf['Simulation']['params']['numbasis'])
                # Get the array containing the magnitude of the difference vector at each point
                # in space
                mag_diff_vec = self.diff_sq(vecs1, vecs2)
                # Check for equal lengths between norm array and diff mag
                # array
                if len(mag_diff_vec) != len(normvec):
                    self.log.error( "The normalization vector has an incorrect number of elements!!!")
                    raise ValueError
                # Error as a percentage should be the square root of the ratio of sum of mag diff vec
                # squared to mag efield squared
                error = np.sqrt(np.sum(mag_diff_vec) / np.sum(normvec))
                errfile.write('%i,%f\n' % (sim2.conf['Simulation']['params']['numbasis'], error))
                sim2.clear_data()
            ref_sim.clear_data()

    def adjacent_error(self, field, exclude=False):
        """Computes the global error between the vector fields of two simulations. This is the sum
        of the magnitude squared of the difference vectors divided by the sum of the magnitude
        squared of the comparison efield vector over the desired section of the simulation cell.
        This computes error between adjacent sims in a sweep through basis terms."""

        self.log.info('Running the adjacent error computation for quantity %s', field)
        # If we need to exclude calculate the indices
        if exclude:
            start, end = self.get_slice(self.sims[0])
            excluded = '_excluded'
        else:
            start = 0
            end = None
            excluded = ''
        base = self.sims[0].conf['General']['results_dir']
        errpath = os.path.join(base, 'adjacenterror_%s%s.dat' % (field, excluded))
        with open(errpath, 'w') as errfile:
            self.log.info('Computing adjacent error for sweep %s', base)
            # For all other sims in the groups, compare to best estimate
            # and write to error file
            for i in range(1, self.num_sims):
                # Set reference sim
                ref_sim = self.sims[i]
                # Get the comparison vector
                vecs1, normvec = self.get_comp_vec(ref_sim, field, start, end)
                sim2 = self.sims[i - 1]
                vecs2, normvec2 = self.get_comp_vec(sim2, field, start, end)
                self.log.info("Computing adjacent error between numbasis %i and numbasis %i",
                              ref_sim.conf['Simulation'][ 'params']['numbasis'],
                              sim2.conf['Simulation']['params']['numbasis'])
                # Get the array containing the magnitude of the difference vector at each point
                # in space
                mag_diff_vec = self.diff_sq(vecs1, vecs2)
                # Check for equal lengths between norm array and diff mag
                # array
                if len(mag_diff_vec) != len(normvec):
                    self.log.error("The normalization vector has an incorrect number of elements!!!")
                    raise ValueError
                # Error as a percentage should be thkkk square root of the ratio of sum of mag diff vec
                # squared to mag efield squared
                error = np.sqrt(np.sum(mag_diff_vec) / np.sum(normvec))
                # self.log.info(str(error))
                errfile.write('%i,%f\n' % (sim2.conf['Simulation']['params']['numbasis'], error))
                sim2.clear_data()
                ref_sim.clear_data()

    def scalar_reduce(self, quantity, avg=False):
        """
        Combine a scalar quantity across all simulations in each group. If
        avg=False then a direct sum is computed, otherwise an average is
        computed
        """

        base = self.sims[0].conf['General']['results_dir']
        self.log.info('Performing scalar reduction for group at %s' % base)
        self.log.debug('QUANTITY: %s'%quantity)
        group_comb = self.sims[0].get_scalar_quantity(quantity)
        self.log.debug(group_comb.dtype)
        self.sims[0].clear_data()
        # This approach is more memory efficient then building a 2D array
        # of all the data from each group and summing along an axis
        for sim in self.sims[1:]:
            self.log.debug(sim.id)
            quant = sim.get_scalar_quantity(quantity)
            self.log.debug(quant.dtype)
            group_comb += quant
            sim.clear_data()
        if avg:
            group_comb = group_comb / self.num_sims
            fname = 'scalar_reduce_avg_%s' % quantity
        else:
            fname = 'scalar_reduce_%s' % quantity
            path = os.path.join(base, fname)
        ftype = self.sims[0].conf['General']['save_as']
        if ftype == 'npz':
            np.save(path, group_comb)
        elif ftype == 'hdf5':
            self.log.warning('FIX HDF5 SCALAR REDUCE SAVING')
            np.save(path, group_comb)
        else:
            raise ValueError('Invalid file type in config')

    def fractional_absorbtion(self, port='Substrate'):
        """
        Computes the fraction of the incident spectrum that is absorbed by
        the device. This is a unitless number, and its interpretation somewhat
        depends on the units you express the incident spectrum in. If you
        expressed your incident spectrum in photon number, this can be
        interpreted as the fraction of incident photons that were absorbed. If
        you expressed your incident spectrum in terms of power per unit area,
        then this can be interpreted as the fraction of incident power per unit
        area that gets absorbed. In summary, its the fraction of whatever you
        put in that is being absorbed by the device.
        """

        base = self.sims[0].conf['General']['results_dir']
        self.log.info('Computing fractional absorbtion for group at %s' % base)
        vals = np.zeros(self.num_sims)
        freqs = np.zeros(self.num_sims)
        wvlgths = np.zeros(self.num_sims)
        spectra = np.zeros(self.num_sims)
        path = self.sims[0].conf['Simulation']['input_power_wv']
        wv_vec, p_vec = np.loadtxt(path, usecols=(0, 2), unpack=True, delimiter=',')
        p_wv = interpolate.interp1d(wv_vec, p_vec, kind='linear',
                                    bounds_error=False, fill_value='extrapolate')
        # Assuming the sims have been grouped by frequency, sum over all of
        # them
        for i, sim in enumerate(self.sims):
            # Unpack data for the port we passed in as an argument
            ref, trans, absorb = sim.data['transmission_data'][port]
            freq = sim.conf['Simulation']['params']['frequency']
            wvlgth = c.c / freq
            wvlgth_nm = wvlgth * 1e9
            freqs[i] = freq
            wvlgths[i] = wvlgth
            # Get solar power from chosen spectrum
            # Get p at wvlength by interpolation
            sun_pow = p_wv(wvlgth_nm)
            spectra[i] = sun_pow * wvlgth_nm
            vals[i] = absorb * sun_pow * wvlgth_nm
            sim.clear_data()
        # Use Trapezoid rule to perform the integration. Note all the
        # necessary factors of the wavelength have already been included
        # above
        wvlgths = wvlgths[::-1]
        vals = vals[::-1]
        spectra = spectra[::-1]
        integrated_absorbtion = intg.trapz(vals, x=wvlgths * 1e9)
        power = intg.trapz(spectra, x=wvlgths * 1e9)
        # factor of 1/10 to convert A*m^-2 to mA*cm^-2
        #wv_fact = c.e/(c.c*c.h*10)
        #wv_fact = .1
        #Jsc = (Jsc*wv_fact)/power
        frac_absorb = integrated_absorbtion / power
        outf = os.path.join(base, 'fractional_absorbtion.dat')
        with open(outf, 'w') as out:
            out.write('%f\n' % frac_absorb)
        self.log.info('Fractional Absorbtion = %f' % frac_absorb)
        return frac_absorb

    def photocurrent_density(self, port='Substrate_bottom', method='flux'):
        """
        Computes photocurrent density assuming perfect carrier collection,
        meaning every absorbed photon gets converted to 1 collected electron.

        The incident power computed using
        :py:meth:`Simulation.get_incident_power`.  See that function for
        details about how the incident power is computed.

        Given some number N frequency values (and simulations at those
        frequencies), the photocurrent density can be computed using

        .. math:: J_{ph} = \\int q \\sum_i^N \\frac{P(f_i)A(f_i)}{E_{photon}}
           :label: Jph

        where

        * :math:`P(f_i)` is the incident power at frequency i
        * :math:`A(f_i)` is the fraction of the incident power that is absorbed
        * :math:`E_{photon} = h f_i` is the energy of the incident photons at
          frequency i.
        * :math:`q` is the fundamental charge

        :param port: The location at which to set the transmission port
        :type port: str
        :param method: The method used to compute the absorbed power. One of
                       either 'flux' or 'integral'
        :type method: str
        :return: The photocurrent density, see :eq:`Jph`
        :rtype: float
        :raises ValueError: if the ``method`` kwarg is not 'flux' or
                            'integral'.  This is a bit of a hack at the moment
                            for testing purposes.
        """

        if method not in ('flux', 'integral'):
            msg = 'Invalid method {} for computing absorbance'.format(method)
            raise ValueError(msg)

        base = os.path.expandvars(self.sims[0].conf['General']['results_dir'])
        self.log.info('Computing photocurrent density for group at %s', base)
        jph_vals = np.zeros(self.num_sims)
        freqs = np.zeros(self.num_sims)
        # Assuming the sims have been grouped by frequency, sum over all of
        # them
        for i, sim in enumerate(self.sims):
            freq = sim.conf['Simulation']['params']['frequency']['value']
            freqs[i] = freq
            E_photon = c.h * freq
            if method == 'flux':
                arr = sim.data['transmission_data']
                print(arr.dtype)
                print(arr)
                _, ref, trans, absorb = arr[arr.port == port.encode('utf-8')][0]
                print(ref, trans, absorb)
                incident_power = sim.get_incident_power()
                jph_vals[i] = incident_power * absorb / E_photon
            else:
                try:
                    abs_arr = sim.data['abs_per_layer']
                except KeyError:
                    abs_arr = sim.absorption_per_layer()
                absorbed_power = np.sum(abs_arr['int_method'])
                jph_vals[i] = absorbed_power / E_photon
            sim.clear_data()
        # factor of 1/10 to convert A*m^-2 to mA*cm^-2
        Jph = .1 * c.e * np.sum(jph_vals)
        outf = os.path.join(base, 'jph_{}.dat'.format(method))
        with open(outf, 'w') as out:
            out.write('%f\n' % Jph)
        self.log.info('Jph = %f', Jph)
        return Jph

    def Jsc_integrated_persim(self):
        for i, sim in enumerate(self.sims):
            try:
                genRate = sim.data['genRate']
            except FileNotFoundError:
                genRate = sim.genRate()
            # Gen rate in cm^-3. Gotta convert lengths here from um to cm
            z_vals = self.sims[0].Z
            x_vals = self.sims[0].X
            y_vals = self.sims[0].Y
            z_integral = intg.trapz(genRate, x=z_vals, axis=0)
            x_integral = intg.trapz(z_integral, x=x_vals, axis=0)
            y_integral = intg.trapz(x_integral, x=y_vals, axis=0)
            # z_integral = intg.simps(genRate, x=z_vals, axis=0)
            # x_integral = intg.simps(z_integral, x=x_vals, axis=0)
            # y_integral = intg.simps(x_integral, x=y_vals, axis=0)
            # Convert period to cm and current to mA
            Jsc = 1000*(c.e/(sim.period*1e-4)**2)*y_integral
            self.log.info('Sim %s Jsc Integrate Value: %f', sim.id, Jsc)


    def Jsc_integrated(self):
        """
        Compute te photocurrent density by performing a volume integral of the
        generation rate
        """
        fname = 'scalar_reduce_genRate.npy'
        base = self.sims[0].conf['General']['results_dir']
        self.log.info('Computing integrated Jsc for group at %s', base)
        path = os.path.join(base, fname)
        try:
            genRate = np.load(path)
        except FileNotFoundError:
            self.scalar_reduce('genRate')
            genRate = np.load(path)
        # Gen rate in cm^-3. Gotta convert lengths here from um to cm
        z_vals = self.sims[0].Z
        x_vals = self.sims[0].X
        y_vals = self.sims[0].Y
        z_integral = intg.trapz(genRate, x=z_vals, axis=0)
        x_integral = intg.trapz(z_integral, x=x_vals, axis=0)
        y_integral = intg.trapz(x_integral, x=y_vals, axis=0)
        # z_integral = intg.simps(genRate, x=z_vals, axis=0)
        # x_integral = intg.simps(z_integral, x=x_vals, axis=0)
        # y_integral = intg.simps(x_integral, x=y_vals, axis=0)
        # Convert period to cm and current to mA
        Jsc = 1000*(c.e/(self.sims[0].period*1e-4)**2)*y_integral
        outf = os.path.join(base, 'jsc_integrated.dat')
        with open(outf, 'w') as out:
            out.write('%f\n' % Jsc)
        self.log.info('Jsc_integrated = %f', Jsc)
        return Jsc

    def weighted_transmissionData(self, port='Substrate'):
        """Computes spectrally weighted absorption,transmission, and reflection"""

        base = self.sims[0].conf['General']['results_dir']
        self.log.info('Computing spectrally weighted transmission data for group at %s' % base)
        abs_vals = np.zeros(self.num_sims)
        ref_vals = np.zeros(self.num_sims)
        trans_vals = np.zeros(self.num_sims)
        freqs = np.zeros(self.num_sims)
        wvlgths = np.zeros(self.num_sims)
        spectra = np.zeros(self.num_sims)
        # Get solar power from chosen spectrum
        path = self.sims[0].conf['Simulation']['input_power_wv']
        wv_vec, p_vec = np.loadtxt(path, usecols=(0, 2), unpack=True, delimiter=',')
        # Get interpolating function for power
        p_wv = interpolate.interp1d(wv_vec, p_vec, kind='linear',
                                    bounds_error=False, fill_value='extrapolate')
        # Assuming the leaves contain frequency values, sum over all of them
        for i, sim in enumerate(self.sims):
            ref, trans, absorb = sim.data['transmission_data'][port]
            freq = sim.conf['Simulation']['params']['frequency']
            wvlgth = c.c / freq
            wvlgth_nm = wvlgth * 1e9
            freqs[i] = freq
            wvlgths[i] = wvlgth
            sun_pow = p_wv(wvlgth_nm)
            spectra[i] = sun_pow * wvlgth_nm
            abs_vals[i] = sun_pow * absorb * wvlgth_nm
            ref_vals[i] = sun_pow * ref * wvlgth_nm
            trans_vals[i] = sun_pow * trans * wvlgth_nm
        # Now integrate all the weighted spectra and divide by the power of
        # the spectra
        wvlgths = wvlgths[::-1]
        abs_vals = abs_vals[::-1]
        ref_vals = ref_vals[::-1]
        trans_vals = trans_vals[::-1]
        spectra = spectra[::-1]
        power = intg.trapz(spectra, x=wvlgths * 1e9)
        wght_ref = intg.trapz(ref_vals, x=wvlgths * 1e9) / power
        wght_abs = intg.trapz(abs_vals, x=wvlgths * 1e9) / power
        wght_trans = intg.trapz(trans_vals, x=wvlgths) / power
        out = os.path.join(base, 'weighted_transmission_data.dat')
        with open(out, 'w') as outf:
            outf.write('# Reflection, Transmission, Absorbtion\n')
            outf.write('%f,%f,%f' % (wght_ref, wght_trans, wght_abs))
        return wght_ref, wght_trans, wght_abs

    def convergence(self, quantity, err_type='global', scale='linear'):
        """Plots the convergence of a field across all available simulations"""

        self.log.info('Plotting convergence')
        base = self.sims[0].conf['General']['base_dir']
        if err_type == 'local':
            fglob = os.path.join(base, 'localerror_%s*.dat' % quantity)
        elif err_type == 'global':
            fglob = os.path.join(base, 'globalerror_%s*.dat' % quantity)
        elif err_type == 'adjacent':
            fglob = os.path.join(base, 'adjacenterror_%s*.dat' % quantity)
        else:
            self.log.error('Attempting to plot an unsupported error type')
            raise ValueError
        paths = glob.glob(fglob)
        for path in paths:
            labels = []
            errors = []
            with open(path, 'r') as datf:
                for line in datf.readlines():
                    lab, err = line.split(',')
                    labels.append(lab)
                    errors.append(err)
            fig = plt.figure(figsize=(9, 7))
            plt.ylabel('M.S.E of %s' % quantity)
            plt.xlabel('Number of Fourier Terms')
            plt.plot(labels, errors)
            plt.yscale(scale)
            # plt.xticks(x,labels,rotation='vertical')
            plt.tight_layout()
            plt.title(os.path.basename(base))
            if self.gconf['General']['save_plots']:
                if '_excluded' in path:
                    excluded = '_excluded'
                else:
                    excluded = ''
                name = '%s_%sconvergence_%s%s.pdf' % (
                    os.path.basename(base), err_type, quantity, excluded)
                path = os.path.join(base, name)
                fig.savefig(path)
            if self.gconf['General']['show_plots']:
                plt.show()
            plt.close(fig)

    def plot_scalar_reduce(self, quantity, plane, pval, draw=False, fixed=None):
        """Plot the result of a particular scalar reduction for each group"""

        sim = self.sims[0]
        base = os.path.expandvars(sim.conf['General']['results_dir'])
        self.log.info('Plotting scalar reduction of %s for quantity %s' % (base, quantity))
        cm = plt.get_cmap('jet')
        max_depth = sim.conf['Simulation']['max_depth']
        period = sim.conf['Simulation']['params']['array_period']
        x = np.arange(0, period, sim.dx)
        y = np.arange(0, period, sim.dy)
        z = np.arange(0, max_depth + sim.dz, sim.dz)
        ftype = sim.conf['General']['save_as']
        if ftype == 'npz':
            globstr = os.path.join(base, 'scalar_reduce*_%s.npy' % quantity)
            files = glob.glob(globstr)
        elif ftype == 'hdf5':
            self.log.warning('FIX LOAD IN GLOBAL SCALAR REDUCE')
            globstr = os.path.join(base, 'scalar_reduce*_%s.npy' % quantity)
            files = glob.glob(globstr)
        else:
            raise ValueError('Incorrect file type in config')
        title = 'Reduction of %s' % quantity
        for datfile in files:
            p = False
            if ftype == 'npz':
                scalar = np.load(datfile)
            elif ftype == 'hdf5':
                self.log.warning('FIX LOAD IN GLOBAL SCALAR REDUCE')
                scalar = np.load(datfile)
            else:
                raise ValueError('Incorrect file type in config')
            cs = self.get_plane(scalar, plane, pval)
            if plane == 'yz' or plane == 'zy':
                labels = ('y [um]', 'z [um]', quantity, title)
                if sim.conf['General']['save_plots']:
                    fname = 'scalar_reduce_%s_plane_2d_yz.pdf' % quantity
                    p = os.path.join(base, fname)
                show = sim.conf['General']['show_plots']
                self.sims[0].heatmap2d(y, z, cs, labels, plane, pval,
                               save_path=p, show=show, draw=draw, fixed=fixed)
            elif plane == 'xz' or plane == 'zx':
                labels = ('x [um]', 'z [um]', quantity, title)
                if sim.conf['General']['save_plots']:
                    fname = 'scalar_reduce_%s_plane_2d_xz.pdf' % quantity
                    p = os.path.join(base, fname)
                show = sim.conf['General']['show_plots']
                self.sims[0].heatmap2d(sim, x, z, cs, labels, plane, pval,
                               save_path=p, show=show, draw=draw, fixed=fixed)
            elif plane == 'xy' or plane == 'yx':
                labels = ('y [um]', 'x [um]', quantity, title)
                if sim.conf['General']['save_plots']:
                    fname = 'scalar_reduce_%s_plane_2d_xy.pdf' % quantity
                    p = os.path.join(base, fname)
                self.sims[0].heatmap2d(sim, x, y, cs, labels, plane, pval,
                               save_path=p, show=show, draw=draw, fixed=fixed)

    def transmission_data(self, absorbance, reflectance, transmission, port='Substrate'):
        """Plot transmissions, absorption, and reflectance assuming leaves are frequency"""

        base = self.sims[0].conf['General']['results_dir']
        self.log.info('Plotting transmission data for group at %s' % base)
        # Assuming the leaves contain frequency values, sum over all of them
        freqs = np.zeros(self.num_sims)
        refl_l = np.zeros(self.num_sims)
        trans_l = np.zeros(self.num_sims)
        absorb_l = np.zeros(self.num_sims)
        for i, sim in enumerate(self.sims):
            # Unpack data for the port we passed in as an argument
            ref, trans, absorb = sim.data['transmission_data'][port]
            freq = sim.conf['Simulation']['params']['frequency']
            freqs[i] = freq
            trans_l[i] = trans
            refl_l[i] = ref
            absorb_l[i] = absorb
        freqs = (c.c / freqs[::-1]) * 1e9
        refl_l = refl_l[::-1]
        absorb_l = absorb_l[::-1]
        trans_l = trans_l[::-1]
        plt.figure()
        if absorbance:
            self.log.info('Plotting absorbance')
            plt.plot(freqs, absorb_l, '-o', label='Absorption')
        if reflectance:
            plt.plot(freqs, refl_l, '-o', label='Reflection')
        if transmission:
            plt.plot(freqs, trans_l, '-o', label='Transmission')
        plt.legend(loc='best')
        figp = os.path.join(base, 'transmission_plots_port%s.pdf'%port)
        plt.xlabel('Wavelength (nm)')
        plt.ylim((0, 1.0))
        plt.savefig(figp)
        plt.close()


def counted(fn):
    def wrapper(self):
        wrapper.called += 1
        return fn(self)
    wrapper.called = 0
    wrapper.__name__ = fn.__name__
    return wrapper

def _crunch_local(sim, gconf):
    sim = Simulation(Config(sim))
    _process(sim, "Cruncher", gconf)
    sim.write_data()
    sim.clear_data()

def _plot_local(sim, gconf):
    sim = Simulation(Config(sim))
    _process(sim, "Plotter", gconf)
    sim.clear_data()

def _crunch_global(sim_group, gconf):
    sims = [Simulation(Config(path)) for path in sim_group]
    sim_group = SimulationGroup(sims)
    _process(sim_group, "Global_Cruncher", gconf)
    for sim in sim_group.sims:
        sim.clear_data()

def _plot_global(sim_group, gconf):
    sims = [Simulation(Config(path)) for path in sim_group]
    sim_group = SimulationGroup(sims)
    _process(sim_group, "Global_Plotter", gconf)
    for sim in sim_group.sims:
        sim.clear_data()

def _call_func(quantity, obj, args):
    """
    Calls an instance method of an object with args
    """

    log = logging.getLogger(__name__)
    try:
        result = getattr(obj, quantity)(*args)
    except AttributeError:
        log.error("Unable to call the following function: %s", quantity)
        raise
    return result

def _process(obj, process, gconf):
    """
    Calls a process on an object. The object could be a Simulation object,
    or a SimulationGroup object. It just loops through the functions
    defined in the process subsection of the Postprocessing section in the
    config file, and uses call_func to call the object's method with the
    names defined in the config.
    """

    to_compute = {quant: data for quant, data in
                  gconf['Postprocessing'][process].items() if
                  data['compute']}
    for quant, data in to_compute.items():
        argsets = data['args']
        if argsets and isinstance(argsets[0], list):
            for argset in argsets:
                if argset:
                    _call_func(quant, obj, argset)
                else:
                    _call_func(quant, obj, [])
        else:
            if argsets:
                _call_func(quant, obj, argsets)
            else:
                _call_func(quant, obj, [])


class Processor(object):
    """
    Generic class for automating the processing of Simulations and
    SimulationGroups
    """

    def __init__(self, global_conf, sims=[], sim_groups=[], failed_sims=[]):
        if os.path.isfile(global_conf):
            self.gconf = Config(os.path.abspath(global_conf))
        else:
            self.gconf = global_conf
        # self.gconf.expand_vars()
        self.log = logging.getLogger(__name__)
        self.log.debug("Processor base init")
        self.sims = sims
        self.sim_groups = sim_groups
        # A place to store any failed sims (i.e sims that are missing their
        # data file)
        self.failed_sims = failed_sims

    def collect_sims(self):
        """
        Collect all the simulations beneath the base of the directory tree
        """

        sims = []
        failed_sims = []
        ftype = self.gconf['General']['save_as']
        # Get correct data file name
        if ftype == 'npz':
            datfile = self.gconf['General']['base_name'] + '.npz'
        elif ftype == 'hdf5':
            datfile = 'sim.hdf5'
        else:
            raise ValueError('Invalid file type specified in config')
        # Find the data files and instantiate Simulation objects
        base = os.path.expandvars(self.gconf['General']['base_dir'])
        self.log.info(base)
        for root, dirs, files in os.walk(base):
            conf_path = os.path.join(root, 'sim_conf.yml')
            if 'sim_conf.yml' in files and datfile in files:
                self.log.info('Gather sim at %s', root)
                sim_obj = Simulation(Config(conf_path))
                # sim_obj.conf.expand_vars()
                sims.append(sim_obj)
            elif 'sim_conf.yml' in files:
                sim_obj = Simulation(Config(conf_path))
                self.log.error('The following sim is missing its data file: %s',
                               sim_obj.conf['General']['sim_dir'])
                failed_sims.append(sim_obj)
        self.sims = sims
        self.failed_sims = failed_sims
        if not sims:
            self.log.error('Unable to find any successful simulations')
            raise RuntimeError('Unable to find any successful simulations')
        return sims, failed_sims

    def get_param_vals(self, parseq):
        """
        Return all possible values of the provided parameter for this sweep
        """

        vals = []
        for sim in self.sims:
            val = sim.conf[parseq]
            if val not in vals:
                vals.append(val)
        return vals

    def filter_by_param(self, pars):
        """Accepts a dict where the keys are parameter names and the values are
        a list of possible values for that parameter. Any simulation whose
        parameter does not match any of the provided values is removed from the
        sims and sim_groups attribute"""

        assert(type(pars) == dict)
        for par, vals in pars.items():
            self.sims = [sim for sim in self.sims if sim.conf[par] in vals]
            groups = []
            for group in self.sim_groups:
                filt_group = [sim for sim in group if sim.conf[par] in vals]
                groups.append(filt_group)
            self.sim_groups = groups
        assert(len(self.sims) >= 1)
        return self.sims, self.sim_groups

    def group_against(self, key, variable_params, sort_key=None):
        """Groups simulations by against particular parameter. Within each
        group, the parameter specified will vary, and all other
        parameters will remain fixed. Populates the sim_groups attribute and
        also returns a list of lists. The simulations with each group will be
        sorted in increasing order of the specified parameter. An optional key
        may be passed in, the groups will be sorted in increasing order of the
        specified key"""

        self.log.info('Grouping sims against: %s', str(key))
        # We need only need a shallow copy of the list containing all the sim
        # objects We don't want to modify the orig list but we wish to share
        # the sim objects the two lists contain
        sims = copy.copy(self.sims)
        sim_groups = [[sims.pop()]]
        # While there are still sims that havent been assigned to a group
        while sims:
            # Get the comparison dict for this sim
            sim = sims.pop()
            val1 = sim.conf[key]
            # We want the specified key to vary, so we remove it from the
            # comparison dict
            del sim.conf[key]
            cmp1 = {'Simulation': sim.conf['Simulation'],
                    'Layers': sim.conf['Layers']}
            match = False
            # Loop through each group, checking if this sim belongs in the
            # group
            for group in sim_groups:
                sim2 = group[0]
                val2 = sim2.conf[key]
                del sim2.conf[key]
                cmp2 = {'Simulation': group[0].conf['Simulation'],
                        'Layers': group[0].conf['Layers']}
                params_same = cmp_dicts(cmp1, cmp2)
                if params_same:
                    match = True
                    # We need to restore the param we removed from the
                    # configuration earlier
                    sim.conf[key] = val1
                    group.append(sim)
                group[0].conf[key] = val2
            # If we didnt find a matching group, we need to create a new group
            # for this simulation
            if not match:
                sim.conf[key] = val1
                sim_groups.append([sim])
        # Get the params that will define the path in the results dir for each
        # group that will be stored
        ag_key = tuple(key[0:-1])
        result_pars = [var for var in variable_params if var != ag_key]
        for group in sim_groups:
            # Sort the individual sims within a group in increasing order of
            # the parameter we are grouping against a
            group.sort(key=lambda sim: sim.conf[key])
            path = '{}/grouped_against_{}'.format(group[0].conf['General']['base_dir'],
                                                  ag_key[-1])
            path = os.path.expandvars(path)
            # If the only variable param is the one we grouped against, make
            # the top dir
            if not result_pars:
                try:
                    os.makedirs(path)
                except OSError:
                    pass
            # Otherwise make the top dir and all the subdirs
            else:
                for par in result_pars:
                    # All sims in the group will have the same values for
                    # result_pars so we can just use the first sim in the group
                    path = os.path.join(path, '{}_{:.4E}/'.format(par[-1],
                                                                  group[0].conf[par]))
                    self.log.info('RESULTS DIR: %s', path)
                    try:
                        os.makedirs(path)
                    except OSError:
                        pass
            for sim in group:
                sim.conf['General']['results_dir'] = path
                outpath = os.path.join(sim.conf['General']['sim_dir'],
                                       'sim_conf.yml')
                outpath = os.path.expandvars(outpath)
                sim.conf.write(outpath)
        # Sort the groups in increasing order of the provided sort key
        if sort_key:
            sim_groups.sort(key=lambda group: group[0].conf[key])
        sim_groups = [SimulationGroup(sims) for sims in sim_groups]
        self.sim_groups = sim_groups
        return sim_groups

    def group_by(self, key, sort_key=None, repopulate=True):
        """
        Groups simulations by the parameter associated with `key` in the
        config. Within each group, the parameter associated with `key` will
        remain fixed, and all other parameters may vary.

        .. note::
        This function repopulates the sim_groups attribute by default. If you
        do not want this behavior, set the `repopulate` kwarg to False


        :param key: The key for the parameter you wish to group by. Must be an
                    iterable of strings.
        :type key: iterable
        :param sort_key: An optional key by which to sort the parameters within
                         each group. For example, group by parameter A but sort
                         each group in increasing order of parameter B. If a
                         callable object is provided, that callable will be
                         applied to each individual simulation in the group to
                         generate the sort key. If an iterable is provided, it
                         will be interpreted as a key in the config and the
                         parameter associated with that key will be used.
        :type sort_key: iterable, callable
        :returns: A singly nested list of lists. Each inner list contains a
                  group of simulations.
        :rtype: list
        """

        self.log.info('Grouping sims by: %s', str(key))
        # This works by storing the different values of the specifed parameter
        # as keys, and a list of sims whose value matches the key as the value
        pdict = {}
        for sim in self.sims:
            if sim.conf[key] in pdict:
                pdict[sim.conf[key]].append(sim)
            else:
                pdict[sim.conf[key]] = [sim]
        # Now all the sims with matching values for the provided key are just
        # the lists located at each key. We sort the groups in increasing order
        # of the provided key
        groups = sorted(pdict.values(), key=lambda group: group[0].conf[key])
        # If specified, sort the sims within each group in increasing order of
        # the provided sorting key
        if sort_key:
            if callable(sort_key):
                for group in groups:
                    group.sort(key=sort_key)
            else:
                for group in groups:
                    group.sort(key=lambda sim: sim.conf[sort_key])
        groups = [SimulationGroup(sims) for sims in groups]
        if repopulate:
            self.sim_groups = groups
        return groups

    def replace(self):
        for i, sim in enumerate(self.sims):
            path = os.path.join(sim.conf['General']['sim_dir'], 'sim_conf.yml')
            self.sims[i] = path

        for i, group in enumerate(self.sim_groups):
            new_group = []
            for sim in group.sims:
                new_group.append(os.path.join(sim.conf['General']['sim_dir'],
                                              'sim_conf.yml'))

            self.sim_groups[i] = new_group

    def call_func(self, quantity, obj, args):
        """
        Calls an instance method of an object with args
        """

        try:
            result = getattr(obj, quantity)(*args)
        except KeyError:
            self.log.error("Unable to call the following function: %s",
                           quantity, exc_info=True, stack_info=True)
            raise
        return result

    def _process(self, obj, process):
        """
        Calls a process on an object. The object could be a Simulation object,
        or a SimulationGroup object. It just loops through the functions
        defined in the process subsection of the Postprocessing section in the
        config file, and uses call_func to call the object's method with the
        names defined in the config.
        """

        self.log.info('Running %s process for obj %s', process, str(obj))
        to_compute = {quant: data for quant, data in
                      self.gconf['Postprocessing'][process].items() if
                      data['compute']}
        for quant, data in to_compute.items():
            argsets = data['args']
            self.log.info('Calling %s with args %s', str(quant), str(argsets))
            if argsets and isinstance(argsets[0], list):
                for argset in argsets:
                    self.log.info('Calling with individual argset %s', str(argset))
                    if argset:
                        self.call_func(quant, obj, argset)
                    else:
                        self.call_func(quant, obj, [])
            else:
                if argsets:
                    self.call_func(quant, obj, argsets)
                else:
                    self.call_func(quant, obj, [])

    def crunch_local(self, sim):
        _crunch_local(sim, self.gconf)

    def crunch_local_all(self):
        self.log.info('Beginning data crunch for all sims ...')
        if not self.gconf['General']['post_parallel']:
            for sim in self.sims:
                _crunch_local(sim, self.gconf)
        else:
            num_procs = self.gconf['General']['num_cores']
            self.log.info('Crunching sims in parallel using %s cores ...', str(num_procs))
            args_list = list(zip(self.sims, repeat(self.gconf)))
            pool = mp.Pool(processes=num_procs)
            pool.starmap(_crunch_local, args_list)
            pool.close()
            pool.join()

    def plot_local(self, sim):
        _plot_local(sim, self.gconf)

    def plot_local_all(self):
        self.log.info('Beginning local plotting for all sims ...')
        if not self.gconf['General']['post_parallel']:
            for sim in self.sims:
                _plot_local(sim, self.gconf)
        else:
            num_procs = self.gconf['General']['num_cores']
            self.log.info('Plotting sims in parallel using %s cores ...', str(num_procs))
            pool = mp.Pool(processes=num_procs)
            args_list = list(zip(self.sims, repeat(self.gconf)))
            pool.starmap(_plot_local, args_list)
            pool.close()
            pool.join()

    def crunch_global(self, sim_group):
        _process(sim_group, "Global_Cruncher", self.gconf)

    def crunch_global_all(self):
        self.log.info('Beginning global data crunch for all sim groups ...')
        if not self.gconf['General']['post_parallel']:
            for group in self.sim_groups:
                _crunch_global(group, self.gconf)
        else:
            num_procs = self.gconf['General']['num_cores']
            self.log.info('Crunching sim groups in parallel using %s cores ...', str(num_procs))
            pool = mp.Pool(processes=num_procs)
            args_list = list(zip(self.sim_groups, repeat(self.gconf)))
            pool.starmap(_crunch_global, args_list)
            pool.close()
            pool.join()

    def plot_global(self, sim_group):
        _process(sim_group, "Global_Plotter", self.gconf)

    def plot_global_all(self):
        self.log.info('Beginning global data plot for all sim groups ...')
        if not self.gconf['General']['post_parallel']:
            for group in self.sim_groups:
                _plot_global(group, self.gconf)
        else:
            num_procs = self.gconf['General']['num_cores']
            self.log.info('Plotting sim groups in parallel using %s cores ...', str(num_procs))
            pool = mp.Pool(processes=num_procs)
            args_list = list(zip(self.sim_groups, repeat(self.gconf)))
            pool.starmap(_plot_global, args_list)
            pool.close()
            pool.join()
