import shutil
# import psutil
import os
import os.path as osp
import posixpath
import sys
import copy
from multiprocessing.pool import Pool
import multiprocessing as mp
import threading
try:
    import Queue
except ImportError:
    import queue as Queue
import numpy as np
import scipy.optimize as optz
import tables as tb
# from tables.node import filenode
import time
import logging
import traceback
# import logging_tree
import S4
import dispy
import scipy.interpolate as spi
import scipy.constants as constants
# import gc3libs
# from gc3libs.core import Core, Engine
from sympy import Circle
from lxml import etree
from lxml.builder import E
# get our custom config object and the logger function
# from . import postprocess as pp
from nanowire.optics.data_manager import HDF5DataManager
from nanowire.utils.utils import (
    make_hash,
    IdFilter,
    get_combos,
    find_inds,
    merge_and_sort,
    arithmetic_arange,
    get_public_ip,
    get_public_iface,
    sorted_dict,
    find_keypaths,
    group_against,
)
from nanowire.optics.utils.utils import (
    get_incident_amplitude,
    get_nk,
)
from nanowire.preprocess import Config
from nanowire.optics.utils.geometry import get_layers

DISPY_LOOKUP = {dispy.DispyJob.Abandoned: 'Abandoned',
                dispy.DispyJob.Cancelled: 'Cancelled',
                dispy.DispyJob.Created: 'Created',
                dispy.DispyJob.Finished: 'Finished',
                dispy.DispyJob.ProvisionalResult: 'ProvisionalResult',
                dispy.DispyJob.Running: 'Running',
                dispy.DispyJob.Terminated: 'Terminated'}

# Configure logging for this module
# Get numeric level safely
logfile = 'logs/simulate.log'
debug = getattr(logging, 'debug'.upper(), None)
info = getattr(logging, 'info'.upper(), None)
warn = getattr(logging, 'warn'.upper(), None)
# Set formatting
formatter = logging.Formatter('%(asctime)s [%(name)s:%(levelname)s]'
                              ' - %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p')
# Create logger
logger = logging.getLogger(__name__)
logger.setLevel(debug)
log_dir, logfile = osp.split(osp.expandvars(logfile))
# Set up file handler
try:
    os.makedirs(log_dir)
except OSError:
    # Log dir already exists
    pass
output_file = osp.join(log_dir, logfile)
fhandler = logging.FileHandler(output_file)
fhandler.setFormatter(formatter)
fhandler.setLevel(debug)
# We dont want log records generated by Simulator instances making it to the
# global simulate.log file
fhandler.addFilter(IdFilter(reject=True))
logger.addHandler(fhandler)
# Logging to console
ch = logging.StreamHandler()
ch.setLevel(info)
ch.setFormatter(formatter)
ch.addFilter(IdFilter(reject=True))
logger.addHandler(ch)


# This will log any uncaught exceptions
def handle_exception(exc_type, exc_value, exc_traceback):
    if issubclass(exc_type, KeyboardInterrupt):
        sys.__excepthook__(exc_type, exc_value, exc_traceback)
        return

    logger.critical("Uncaught exception", exc_info=(exc_type, exc_value,
                                                    exc_traceback))


sys.excepthook = handle_exception


def update_sim(conf, samples, q=None):
    """
    Wrapper for updating field arrays for a simulation. Expects the Config
    for the simulation as an argument.
    """

    try:
        log = logging.getLogger(__name__)
        start = time.time()
        conf['General']['z_samples'] = samples
        sim = Simulator(copy.deepcopy(conf))
        sim.setup()
        log.info('Updating arrays for sim %s', sim.ID[0:10])
        sim.update_zsamples()
    except:
        trace = traceback.format_exc()
        msg = 'Sim {} raised the following exception:\n{}'.format(sim.ID,
                                                                  trace)
        log.error(msg)
        # We might encounter an exception before the logger instance for this
        # sim gets created
        try:
            sim.log.error(trace)
        except AttributeError:
            pass
        raise


def run_sim(conf, output_dir):
    """
    Runs a single simulation given a Config object representing the
    configuration for the simulation and a string pointing to a directory the
    simulation should write its output data to.

    .. note:: It is important that the Config object has the correct structure
    for the simulation to run properly

    :param conf: A Config object representing the configuration for this
    particular simulation
    :type conf: nanowire.preprocess.config.Config
    :param output_dir: Directory the simulation will write its data to
    :type output_dir: str
    """

    log = logging.getLogger(__name__)
    try:
        start = time.time()
        sim = Simulator(copy.deepcopy(conf))
        sim.setup()
        log.info('Executing sim %s', sim.ID[0:10])
        sim.save_all()
        # sim.mode_solve()
        sim.clean_sim()
        end = time.time()
        runtime = end - start
        log.info('Simulation %s completed in %.2f seconds!', sim.ID[0:10], runtime)
    except:
        trace = traceback.format_exc()
        msg = 'Sim {} raised the following exception:\n{}'.format(sim.ID,
                                                                  trace)
        log.error(msg)
        # We might encounter an exception before the logger instance for this
        # sim gets created
        try:
            sim.log.error(trace)
        except AttributeError:
            pass
    return None

def run_sim_dispy(conf):
    try:
        import sys
        import os
        import logging
        import time
        import copy
        import dispy
        import socket
        from nanowire.optics.data_manager import HDF5DataManager, NPZDataManager
        from nanowire.optics.utils.utils import (
            make_hash,
            get_combos,
            IdFilter,
            get_incident_amplitude,
            find_inds,
            merge_and_sort,
            arithmetic_arange
        )
        from nanowire.optics.utils.config import Config
        from nanowire.optics.utils.geometry import Layer, get_layers
        from nanowire.optics.simulate import Simulator
        log = logging.getLogger(__name__)
        start = time.time()
        # act_path = osp.expandvars('$HOME/.virtualenvs/nanowire/bin/activate_this.py')
        # global_vars = globals()
        # global_vars['__file__'] = act_path
        # exec(compile(open(act_path, "rb").read(), act_path, 'exec'),
        #      global_vars, locals())
        sim = Simulator(copy.deepcopy(conf), q=None)
        # return 'returned a thing'
        if not sim.conf.variable_thickness:
            sim.setup()
            # rel_dir = osp.join('./', osp.basename(sim.dir))
            # rel_dir = osp.basename(sim.dir)
            # sim.dir = rel_dir
            # sim.conf['General']['sim_dir'] = rel_dir
            log.info('Executing sim %s', sim.ID[0:10])
            sim.save_all()
            for f in os.listdir(sim.dir):
                fpath = osp.join(sim.dir, f)
                dispy_send_file(fpath)
            # path = osp.join(osp.basename(sim.dir), 'sim.hdf5')
            # sim.q.put(path, block=True)
            # sim.mode_solve()
        else:
            log.info('Computing a thickness sweep at %s' % sim.ID[0:10])
            orig_id = sim.ID[0:10]
            # Get all combinations of layer thicknesses
            keys, combos = get_combos(sim.conf, sim.conf.variable_thickness)
            # Update base directory to new sub directory
            sim.conf['General']['base_dir'] = sim.dir
            # Set things up for the first combo
            first_combo = combos.pop()
            # First update all the thicknesses in the config. We make a copy of the
            # list because it gets continually updated in the config object
            var_thickness = sim.conf.variable_thickness
            for i, param_val in enumerate(first_combo):
                keyseq = var_thickness[i]
                sim.conf[keyseq] = param_val
            # With all the params updated we can now run substutions and
            # evaluations in the config that make have referred to some thickness
            # data, then make the subdir from the sim.ID and get the data
            sim.evaluate_config()
            sim.update_id()
            try:
                os.makedirs(sim.dir)
            except OSError:
                pass
            sim.make_logger()
            subpath = osp.join(orig_id, sim.ID[0:10])
            log.info('Computing initial thickness at %s', subpath)
            sim.save_all()
            # path = osp.join(sim.dir, 'data.hdf5')
            # sim.q.put(path, block=True)
            # Now we can repeat the same exact process, but instead of rebuilding
            # the device we just update the thicknesses
            for combo in combos:
                for i, param_val in enumerate(combo):
                    keyseq = var_thickness[i]
                    sim.conf[keyseq] = param_val
                sim.update_id()
                subpath = osp.join(orig_id, sim.ID[0:10])
                log.info('Computing additional thickness at %s', subpath)
                os.makedirs(sim.dir)
                sim.save_all(update=True)
                # path = osp.join(sim.dir, 'data.hdf5')
                # sim.q.put(path, block=True)
        end = time.time()
        runtime = end - start
        log.info('Simulation %s completed in %.2f seconds!', sim.ID[0:10], runtime)
        sim.clean_sim()
    except Exception as e:
        print(traceback.format_exc())
        raise
    return runtime

class LayerFlux(tb.IsDescription):
    layer = tb.StringCol(60, pos=0)
    forward = tb.ComplexCol(pos=1, itemsize=8)
    backward = tb.ComplexCol(pos=2, itemsize=8)


class SimulationManager:

    """
    A class to manage running many simulations either in series or in parallel
    using a variety of different execution backends
    """

    def __init__(self, gconf, base_dir='', log_level='INFO'):
        self.gconf = gconf
        lfile = osp.join(self.gconf['General']['base_dir'],
                             'logs/sim_manager.log')
        try:
            log_level = self.gconf['General']['log_level']
        except KeyError:
            pass
        # self.log = configure_logger(level=log_level, console=True,
        #                             logfile=lfile, name=__name__)
        self.log = logging.getLogger(__name__)
        self.sim_confs = {}
        self.t_sweeps = {}

    def load_confs(self, db, base_dir='', query='', table_path='/',
                   table_name='simulations'):
        """
        Load configs from disk

        Collect all the simulations contained in the HDF5 database file located
        at filesystem path `db` satisfying the query `query`.

        Parameters
        ----------
        db : str
            A path to an HDF5 file containing the database of simulation
            configs
        base_dir : str, optional
            The base directory of the directory tree that all simulations will
            dump their output data into. If not specified, defaults to the
            directory of the database file.
        query : str, optional
            A query string conforming to PyTables table.where syntax specifying
            which configs should be loaded from the HDF5 database. If not
            specified, all configs in the database are loaded
        table_path : str, optional
            String specifying path inside the HDF5 database to the group
            containing the HDF5 simulations table. Default: '/'
        table_path : str, optional
            String specifying the name of the HDF5 simulations table.
            Default: 'simulations'

        Returns
        -------
        list
            A list of :py:class:`nanowire.preprocess.config.Config` objects
        """

        # Find the data files and instantiate Config objects
        if not base_dir:
            base_dir = osp.dirname(db)
        self.log.info(base_dir)
        with tb.open_file(db, 'r') as hdf:
            table = hdf.get_node(table_path, name=table_name,
                                 classname='Table')
            confs = {}
            if query:
                condvars = {k.replace('/', '__'): v
                            for k, v in table.colinstances.items()}
                for row in table.read_where(query, condvars=condvars):
                    short_id = row['ID'].decode()[0:10]
                    conf_path = osp.join(base_dir, short_id, 'sim_conf.yml')
                    self.log.info('Loading config: %s', conf_path)
                    conf = Config.from_array(row, skip_fields=['ID'],
                                             skip_keys=['General'])
                    if row['ID'].decode() != conf.ID:
                        raise ValueError('ID in database and ID of loaded '
                                         'config do not match')
                    confs[conf.ID] = (conf, conf_path)
            else:
                for row in table.read():
                    short_id = row['ID'].decode()[0:10]
                    conf_path = osp.join(base_dir, short_id, 'sim_conf.yml')
                    self.log.info('Loading config: %s', conf_path)
                    conf = Config.from_array(row, skip_fields=['ID'],
                                             skip_keys=['General'])
                    if row['ID'].decode() != conf.ID:
                        raise ValueError('ID in database and ID of loaded '
                                         'config do not match')
                    confs[conf.ID] = (conf, conf_path)
        confs_list = [tup[0] for tup in confs.values()]
        thickness_paths = find_keypaths(confs_list[0], 'thickness')
        # We need to handle the case of thickness sweeps to take advantage of
        # a core efficiency of RCWA, which is that thickness sweeps should come
        # for free. t_sweeps is a dict whose keys and values are both
        # simulation IDs. The keys are ID's of simulations who have a different
        # thickness from the corresponding value, but otherwise have identical
        # parameters. The values in the dict will be the simulations we
        # actually run, and the keys are simulations whose solution will just
        # point to the corresponding value
        t_sweeps = {}
        for path in thickness_paths:
            print(path)
            # Skip max_depth when comparing because it depends on layer
            # thicknesses
            groups = group_against(confs_list, path,
                                   skip_keys=['Simulation/max_depth'])
            for i, b in enumerate([len(group) > 1 for group in groups]):
                if b:
                    self.log.info('Found thickness sweep over %s', path)
                    keep_id = groups[i][0].ID
                    for c in groups[i][1:]:
                        t_sweeps[c.ID] = keep_id
        print(t_sweeps)
        print(len(list(t_sweeps.keys())))
        print(len(set(t_sweeps.keys())))
        print(len(list(t_sweeps.values())))
        print(len(set(t_sweeps.values())))
        self.t_sweeps = t_sweeps
        # for root, dirs, files in os.walk(base_dir):
        #     if os.path.basename(root) in short_ids and 'sim_conf.yml' in files:
        #         conf_path = osp.join(root, 'sim_conf.yml')
        #         self.log.info('Loading config: %s', conf_path)
        #         conf_obj = Config.fromFile(conf_path)
        #         confs.append((conf_path, conf_obj))
        self.sim_confs = confs
        if not confs:
            self.log.error('Unable to find any configs')
            raise RuntimeError('Unable to find any configs')
        return confs

    def filter_sims(self, filter_dict):
        """
        Remove Configs from the self.sim_confs attribute based on the
        filter_dict
        """
        raise NotImplementedError


    def run_serial(self, to_run, func=run_sim, args=(), kwargs={}):
        """
        Apply the provided function `func` to all the loaded Config objects
        serially.  args and kwargs are passed on to the provided function
        unmodified using the usual *args and **kwargs argument expansion.

        :param func: A Python callable that consumes a Config object as its
        first positional argument, and any number of positional arguments and
        keywords arguments thereafter. So, signature must be:
            func(conf, *args, **kwargs)
        :type func: callable
        :param args: A tuple of extra arguments to be passed to the provided
        callable
        :type args: tuple
        :param kwargs: A tuple of extra keyword arguments to be passed to the
        provided callable
        :type kwargs: dict
        """
        self.log.info('Executing sims serially')
        counter = 0
        total = len(to_run)
        for conf, conf_path in to_run:
            func(conf, conf_path)
            counter += 1
            self.log.info('%d out of %d simulations complete', counter, total)

    def run_parallel(self, to_run, *args, func=run_sim, **kwargs):
        self.log.info('Total sims to execute: %i', len(self.sim_confs))
        num_procs = self.gconf['General']['num_cores']
        if num_procs > len(self.sim_confs):
            num_procs = len(self.sim_confs)
        self.log.info('Executing sims in parallel using %i cores ...', num_procs)
        pool = mp.Pool(processes=num_procs)
        total_sims = len(self.sim_confs)
        remaining_sims = len(self.sim_confs)
        def callback(ind):
            callback.remaining_sims -= 1
            callback.log.info('%i out of %i simulations remaining'%(callback.remaining_sims,
                                                            callback.total_sims))
            return None
        callback.remaining_sims = remaining_sims
        callback.total_sims = total_sims
        callback.log = self.log
        results = {}
        self.log.debug('Entering try, except pool clause')
        try:
            for ind, (conf, conf_path) in enumerate(self.sim_confs.values()):
                res = pool.apply_async(func, (conf, conf_path, *args),
                                       **kwargs,
                                       callback=callback)
                results[ind] = res
            # self.log.debug('Closing pool')
            # pool.close()
            self.log.debug("Waiting on results")
            self.log.debug('Results before wait loop: %s',
                           str(list(results.keys())))
            # while len(results) > num_procs:
            while results:
                inds = list(results.keys())
                for ind in inds:
                    # We need to add this really long timeout so that
                    # subprocesses receive keyboard interrupts. If our
                    # simulations take longer than this timeout, an exception
                    # would be raised but that should never happen
                    res = results[ind]
                    self.log.debug('Sim #%i', ind)
                    if res.ready():
                        success = res.successful()
                        if success:
                            self.log.debug('Sim #%i completed successfully!', ind)
                            res.get(10)
                            self.log.debug('Done getting Sim #%i', ind)
                        else:
                            self.log.warning('Sim #%i raised exception!',
                                             ind)
                            res.wait(10)
                            # try:
                            #     res.get(100)
                            # except Exception as e:
                            #     self.log.warning('Sim #%i raised following'
                            #                      ' exception: %s', ind,
                            #                      traceback.format_exc())
                        del results[ind]
                    else:
                        self.log.debug('Sim #%i not ready', ind)
                self.log.debug('Cleaned results: %s',
                               str(list(results.keys())))
                time.sleep(1)

                # res.wait(99999999)
                # res.get(99999999)
                # self.log.debug('Number of items in queue: %i',
                #                self.write_queue.qsize())
            self.log.debug('Closing pool')
            pool.close()
            self.log.debug('Finished waiting')
            self.log.debug('Joining pool')
            pool.join()
        except KeyboardInterrupt:
            pool.terminate()
            pool.join()

    def run_dispy(self, func=run_sim_dispy):
        """
        Run jobs in parallel using dispy
        """
        import time
        log = logging.getLogger(__name__)
        log.info('Executing jobs using dispy cluster')
        # log.info("Beginning dispy submit procedure")
        try:
            nodes = self.gconf['General']['nodes']
            ip = self.gconf['General']['ip_addr']
        except KeyError:
            log.error("Need to specify 'nodes' and 'ip_addr' entries in "
                      "General section")
        if ip == 'auto':
            pub_iface = get_public_iface()
            ip = get_public_ip(pub_iface)
        node_allocs = []
        for node in nodes:
            # If its not a string, hopefully it's a length 2 list or tuple
            # with (str, int) = (ip_addr, port_number)
            if not isinstance(node, str):
                node_allocs.append(dispy.NodeAllocate(node[0], port=node[1]))
            # Use default port locally
            elif node == 'local':
                node_allocs.append(dispy.NodeAllocate(ip))
            else:
                node_allocs.append(dispy.NodeAllocate(node))
        cluster = dispy.JobCluster(run_sim_dispy,
                                   dest_path=time.strftime('%Y-%m-%d'),
                                   cleanup=True,
                                   # cleanup=False, loglevel=dispy.logger.DEBUG,
                                   nodes=node_allocs, ip_addr=ip)
        # Wait until we connect to at least one node
        while len(cluster.status().nodes) == 0:
            time.sleep(1)
        cluster.print_status()
        jobs = {}
        for i, (conf, conf_path) in enumerate(self.sim_confs.values()):
            job = cluster.submit(conf)
            job.id = i
            jobs[i] = job
            stat = DISPY_LOOKUP[job.status]
            log.info('Job ID: {}, Status: {}'.format(i, stat))
        while jobs:
            toremove = []
            for job_id, job in jobs.items():
                status = DISPY_LOOKUP[job.status]
                if (job.status == dispy.DispyJob.Finished
                        or job.status in (dispy.DispyJob.Terminated, dispy.DispyJob.Cancelled,
                                          dispy.DispyJob.Abandoned)):
                    toremove.append(job_id)
            for job_id in toremove:
                job = jobs[job_id]
                stat = DISPY_LOOKUP[job.status]
                time = job.result
                if job.status == dispy.DispyJob.Terminated:
                    log.info('Job ID: %i, Status: %s, Exception:\n%s',
                             job_id, stat, job.exception)
                else:
                    log.info('Job ID: %i, Status: %s, Runtime: %f s'
                             ', Host: %s', job_id, stat, time, job.ip_addr)
                del jobs[job_id]
        return None

    def run(self, *args, func=run_sim, **kwargs):
        """
        Run the loaded configurations in parallel by applying the provided func
        (default run_sim) to each dict using the Python multiprocessing library
        and the apply_async function. We do this instead of applying to an
        actual Simulator object because the Simulator objects are not pickeable
        and thus cannot be parallelized by the multiprocessing lib
        """

        if self.t_sweeps:
            to_run_ids = set(self.t_sweeps.values())
            to_run = [self.sim_confs[ID] for ID in to_run_ids]
        else:
            to_run = list(self.sim_confs.values())
        self.log.info('Total sims to execute: %i', len(to_run))
        runners = {'serial': self.run_serial, 'parallel': self.run_parallel,
                   'dispy': self.run_dispy}
        mode = self.gconf['General']['execution']
        # if self.gconf['General']['execution'] == 'serial':
        #     self.run_serial(to_run, func=func)
        # elif self.gconf['General']['execution'] == 'parallel':
        #     self.run_parallel(to_run, func=func)
        # elif self.gconf['General']['execution'] == 'dispy':
        #     self.run_dispy(to_run)
        runners[mode](to_run)
        self.log.info('Finished executing jobs!')
        if self.t_sweeps:
            self.log.info('Linking thickness sweeps to solutions')
            to_run = []
            for dup_id, ran_id in self.t_sweeps.items():
                print("dup_id = {}".format(dup_id))
                print("ran_id = {}".format(ran_id))
                sol_file = self.sim_confs[ran_id][0]['General/solution_file']
                existing_dir = os.path.dirname(self.sim_confs[ran_id][1])
                existing_sol = os.path.join(existing_dir, sol_file)
                dup_dir = os.path.dirname(self.sim_confs[dup_id][1])
                dup_sol = os.path.join(dup_dir, sol_file)
                try:
                    os.link(existing_sol, dup_sol)
                except FileExistsError:
                    pass
                to_run.append(self.sim_confs[dup_id])
            self.log.info('Total sims to execute: %i', len(to_run))
            runners[mode](to_run)


    # def run(self, *args, filter_dict={}, load=False, func=run_sim, **kwargs):
    #     """
    #     The main run methods that decides what kind of simulation to run based
    #     on the provided config objects
    #     """

    #     if not self.gconf.optimized:
    #         # Get all the sims
    #         if load:
    #             self.load_confs()
    #         else:
    #             self.make_confs()

    #         if filter_dict:
    #             for k, vals in filter_dict.items():
    #                 par = [ks for ks in k.split('.')]
    #                 vals = list(map(type(self.sim_confs[0][par]), vals))
    #                 self.sim_confs = [c for c in self.sim_confs if c[par] in vals]
    #         self.log.info("Executing job campaign")
    #         self.execute_jobs(func=func, *args, **kwargs)
    #     elif self.gconf.optimized:
    #         self.run_optimization()
    #     else:
    #         self.log.error('Unsupported configuration for a simulation run. Not a '
    #                        'single sim, sweep, or optimization. Make sure your sweeps are '
    #                        'configured correctly, and if you are running an optimization '
    #                        'make sure you do not have any sorting parameters specified')


class Simulator:

    def __init__(self, conf):
        self.conf = conf
        numbasis = self.conf['Simulation']['numbasis']
        period = self.conf['Simulation']['array_period']
        self.ID = conf.ID
        sim_dir = self.ID[0:10]
        self.conf['General']['sim_dir'] = sim_dir
        self.base = osp.realpath(osp.expandvars(self.conf['General']['base_dir']))
        self.dir = osp.expandvars(sim_dir)
        self.path = osp.join(self.base, self.dir)
        self.s4 = S4.New(Lattice=((period, 0), (0, period)),
                         NumBasis=int(round(numbasis)))
        self.data = None
        self.runtime = 0
        self.period = period

    def __del__(self):
        """
        Need to make sure we close the file descriptor for the fileHandler that
        this instance attached to the module level logger. If we don't, we'll
        eventually use up all the available file descriptors on the system
        """
        self._clean_logger()
        if self.conf['General']['save_as'] == 'hdf5':
            self.hdf5.close()


    def _clean_logger(self):
        """
        Cleans up all the logging stuff associated with this instance
        """
        # Sometimes we hit an error before the log object gets created and
        # assigned as an attribute. Without the try, except we would get an
        # attribute error which makes error messages confusing and useless
        try:
            self.fhandler.close()
            module_logger = logging.getLogger(__name__)
            module_logger.removeHandler(self.fhandler)
        except AttributeError:
            pass

    def setup(self, skip_hash=False):
        """
        Runs all the necessary setup functions so one can begin running the
        simulation and collecting data
        """
        try:
            os.makedirs(self.path)
        except OSError:
            pass
        self.make_logger()
        self.data = self._get_data_manager()
        self.get_layers()
        self.make_coord_arrays()
        self.configure()
        self.build_device()
        self.set_excitation()

    def make_logger(self, log_level='info'):
        """Makes the logger for this simulation"""
        self._clean_logger()
        # Add the file handler for this instance's log file and attach it to
        # the module level logger
        self.fhandler = logging.FileHandler(osp.join(self.path, 'sim.log'))
        self.fhandler.addFilter(IdFilter(ID=self.ID))
        formatter = logging.Formatter('%(asctime)s [%(name)s:%(levelname)s] - %(message)s',datefmt='%m/%d/%Y %I:%M:%S %p')
        self.fhandler.setFormatter(formatter)
        self.fhandler.setLevel(logging.DEBUG)
        log = logging.getLogger(__name__)
        log.addHandler(self.fhandler)
        # Store the logger adapter to the module level logger as an attribute.
        # We use this to log in any methods, and the sim.ID of this instance
        # will get stored in the log record
        self.log = logging.LoggerAdapter(log, {'ID': self.ID})
        self.log.debug('Logger initialized')

    def _get_data_manager(self):
        """
        Factory function that instantiates the correct data manager object
        depending on the file type specified in the config
        """

        ftype = self.conf['General']['save_as']

        if not ftype:
            return {}
        elif ftype == 'hdf5':
            self.open_hdf5()
            return HDF5DataManager(self.conf, self.log)
        else:
            m = 'Invalid value {} in config at' \
                ' General.save_as'.format(self.conf['General']['save_as'])
            raise ValueError(m)

    def get_layers(self):
        self.layers = get_layers(self)

    def make_coord_arrays(self):
        """
        Set the attributes that define the spatial coordinate arrays. We can't
        do this in __init__ because if we are doing a thickness sweep then
        layer thicknesses and hence max_depth have not yet been resolved in the
        config
        """

        self.xsamps = self.conf['General']['x_samples']
        self.ysamps = self.conf['General']['y_samples']
        samps_dict = self.conf['General']['sample_dict']
        if samps_dict:
            zcoords = []
            for lname, layer in self.layers.items():
                if isinstance(samps_dict[lname], int):
                    z_vals = np.linspace(layer.start, layer.end,
                                         samps_dict[lname])
                else:
                    args = [layer.start, layer.end, *samps_dict[lname]]
                    z_vals = arithmetic_arange(*args)
                zcoords.append(z_vals)
            self.Z = np.concatenate(zcoords)
        elif type(self.conf['General']['z_samples']) == list:
            self.zsamps = len(self.conf['General']['z_samples'])
            self.Z = np.asarray(self.conf['General']['z_samples'])
        else:
            self.zsamps = self.conf['General']['z_samples']
            max_depth = self.conf['Simulation']['max_depth']
            if max_depth:
                self.log.debug('Computing up to depth of {} '
                               'microns'.format(max_depth))
                self.Z = np.linspace(0, max_depth, self.zsamps)
            else:
                self.log.debug('Computing for entire device')
                height = self.get_height()
                self.Z = np.linspace(0, height, self.zsamps)
        self.X = np.linspace(0, self.period, self.xsamps)
        self.Y = np.linspace(0, self.period, self.ysamps)
        self.dx = self.X[1] - self.X[0]
        self.dy = self.Y[1] - self.Y[0]
        self.data.update({"xcoords": self.X, "ycoords": self.Y,
                          "zcoords": self.Z})

    def configure(self):
        """Configure options for the RCWA solver"""
        if self.conf['General']['output_pattern']:
            prefix = osp.join(self.ID[0:10], "VectorField")
            self.s4.SetOptions(BasisFieldDumpPrefix=prefix, **self.conf['Solver'])
        else:
            self.s4.SetOptions(**self.conf['Solver'])

    def build_device(self):
        """Build the device geometry"""

        # First define all the materials
        for mat, mat_path in self.conf['Materials'].items():
            eps = self._get_epsilon(osp.expandvars(mat_path))
            self.s4.SetMaterial(Name=mat, Epsilon=eps)
        self.s4.SetMaterial(Name='vacuum', Epsilon=complex(1, 0))
        # self.layers is an ordered_dict which has been properly sorted because
        # order DOES matter. Light will be incident upon the first layer
        # specified
        for layer_name, layer in self.layers.items():
            self.log.debug('Building layer: %s' % layer_name)
            base_mat = layer.base_material
            layer_t = layer.thickness
            self.s4.AddLayer(Name=layer_name, Thickness=layer_t,
                             Material=base_mat)
            self.log.debug('Building geometry in layer: {}'.format(layer_name))
            for shape_name, (shape, shape_mat) in layer.shapes.items():
                self.log.debug('Building object %s of type %s', shape_name,
                               shape)
                if isinstance(shape, Circle):
                    self.s4.SetRegionCircle(Layer=layer_name, Material=shape_mat,
                                            Center=tuple(shape.center),
                                            Radius=float(shape.radius))
                else:
                    raise NotImplementedError('Shape %s is not yet implemented'%shape)

    def add_interpolator(self, key, method='linear'):
        """
        Add an interpolator method to this object for the data located at
        self.data[key]. The data must reside on a regular grid, but the grid
        points do not need to be evenly spaced
        """

        values = self.data[key]
        points = (self.Z, self.X, self.Y)
        rgi = spi.RegularGridInterpolator(points, values, method=method,
                                          bounds_error=True)
        setattr(self, key, rgi)

    def open_hdf5(self):
        fpath = osp.join(self.path, 'sim.hdf5')
        self.hdf5 = tb.open_file(fpath, 'a')

    def clean_sim(self):
        try:
            self._clean_logger()
            del self.log
            del self.s4
            self.data.close()
        except AttributeError:
            pass


    def set_numbasis(self, numbasis):
        """
        Set the number of basis terms. This function updates the number of
        basis terms in the config and also updates the s4 attribute. This is
        necessary because the interface to S4 (i.e the object stored at
        self.s4) requires the number of basis terms to be provided to the
        constructor of that object.

        .. note:: You will need to call self.setup() after calling this
        function
        """
        self.conf['Simulation']['numbasis'] = numbasis
        self.s4 = S4.New(Lattice=((self.period, 0), (0, self.period)),
                         NumBasis=int(round(numbasis)))
        self.setup()

    def set_period(self, period):
        """
        Set the periodicity of the square array. This function updates the
        number of basis terms in the config and also updates the s4 attribute.
        This is necessary because the interface to S4 (i.e the object stored at
        self.s4) requires the lattice vectors of the unit cell to be provided
        to the constructor of that object.

        .. note:: You will need to call self.setup() after calling this
        function
        """
        self.conf['Simulation']['array_period'] = period
        numbasis = self.conf['Simulation']['numbasis']
        self.s4 = S4.New(Lattice=((period, 0), (0, period)),
                         NumBasis=int(round(numbasis)))
        self.setup()

    def _get_epsilon(self, path):
        """Returns complex dielectric constant for a material by pulling in nk
        text file, interpolating, computing nk values at freq, and
        converting"""
        freq = self.conf['Simulation']['frequency']
        # Get data
        n, k = get_nk(path, freq)
        # Convert to dielectric constant
        # NOTE!!: This assumes the relative magnetic permability (mew) is 1
        epsilon_real = n**2 - k**2
        epsilon_imag = 2 * n * k
        epsilon = complex(epsilon_real, epsilon_imag)
        return epsilon

    def _get_incident_amplitude_anna(self):
        freq = self.conf['Simulation']['frequency']
        path = '$HOME/software/nanowire/nanowire/spectra/Input_sun_power.txt'
        freq_vec, p_vec = np.loadtxt(osp.expandvars(path), unpack=True)
        p_of_f = spi.interp1d(freq_vec, p_vec)
        intensity = p_of_f(freq)
        self.log.debug('Incident Intensity: %s', str(intensity))
        area = self.period*self.period
        power = intensity*area
        self.log.debug('Incident Power: %s', str(power))
        # We need to reduce amplitude of the incident wave depending on
        #  incident polar angle
        # E = np.sqrt(2 * constants.c*constants.mu_0*f_p(freq))*np.cos(polar_angle)
        E = np.sqrt(2 * constants.c * constants.mu_0 * intensity)
        self.log.debug('Incident Amplitude: %s', str(E))
        return E

    def set_excitation(self):
        """Sets the exciting plane wave for the simulation"""
        f_phys = self.conf['Simulation']['frequency']
        self.log.debug('Physical Frequency = %E' % f_phys)
        c_conv = constants.c / self.conf['Simulation']['base_unit']
        f_conv = f_phys / c_conv
        self.s4.SetFrequency(f_conv)
        polar = self.conf['Simulation']['polar_angle']
        azimuth = self.conf['Simulation']['azimuthal_angle']
        # To define circularly polarized light from the point of view of the
        # source, basically just stick a j
        # (imaginary number) in front of one of your components. The component
        # you choose to stick the j in front of is a matter of convention. In
        # S4, if the incident azimuthal angle is 0, p-polarization is along
        # x-axis. Here, we choose to make the y-component imaginary. The
        # handedness is determined both by the component you stick the j in
        # front of and the sign of the imaginary component. In our convention,
        # minus sign means rhcp, plus sign means lhcp. To be circularly
        # polarized, the magnitudes of the two components must be the same.
        # This means E-field vector rotates clockwise when observed from POV of
        # source. Left handed = counterclockwise.
        # TODO: This might not be properly generalized to handle
        # polarized light if the azimuth angle IS NOT 0. Might need some extra
        # factors of cos/sin of azimuth to gen proper projections onto x/y axes
        polarization = self.conf['Simulation']['polarization']
        if polarization == 'rhcp':
            # Right hand circularly polarized
            self.s4.SetExcitationPlanewave(IncidenceAngles=(polar, azimuth),
                                           sAmplitude=complex(0, -1),
                                           pAmplitude=complex(1, 0))
        elif polarization == 'lhcp':
            # Left hand circularly polarized
            self.s4.SetExcitationPlanewave(IncidenceAngles=(polar, azimuth),
                                           sAmplitude=complex(0, 1),
                                           pAmplitude=complex(1, 0))
        elif polarization == 'lpx':
            # Linearly polarized along x axis (TM polarixation)
            self.s4.SetExcitationPlanewave(IncidenceAngles=(polar, azimuth),
                                           sAmplitude=complex(0, 0),
                                           pAmplitude=complex(1, 0))
        elif polarization == 'lpy':
            # Linearly polarized along y axis (TE polarization)
            self.s4.SetExcitationPlanewave(IncidenceAngles=(polar, azimuth),
                                           sAmplitude=complex(1, 0),
                                           pAmplitude=complex(0, 0))
        else:
            raise ValueError('Invalid polarization specification')

    def get_height(self):
        """Get the total height of the device"""
        return sum(layer.thicknes for layer in self.layers.values())

    def set_lattice(self, period):
        """Updates the S4 simulation object with a new array period"""
        numbasis = self.conf['Simulation']['numbasis']
        self.s4 = S4.New(Lattice=((period, 0), (0, period)), NumBasis=numbasis)

    def set_basis(self, numbasis):
        """Updates the S4 simulation object with a new set of basis terms"""
        period = self.conf['Simulation']['array_period']
        self.s4 = S4.New(Lattice=((period, 0), (0, period)), NumBasis=numbasis)

    def update_thicknesses(self):
        """Updates all layer thicknesses without rebuilding the device. This
        allows reuse of any layer eigenmodes already computed and utilizes a
        fundamental efficiency of the RCWA solver"""
        for layer, ldata in self.conf['Layers'].items():
            thickness = ldata['thickness']
            self.s4.SetLayerThickness(Layer=layer, Thickness=thickness)

    # @do_profile(out='$nano/tests/profile_writing/line_profiler.txt', follow=[])
    def compute_fields(self, zvals=None):
        """
        Constructs and returns a full 3D numpy array for each vector component
        of the electric field (return order Ex, Ey, Ez) according to the real
        space sampling points specified in the config file.
        """

        if zvals is None:
            zvals = self.Z

        self.log.debug('Computing fields ...')
        Ex = np.zeros((len(zvals), self.xsamps, self.ysamps),
                      dtype=np.complex128)
        Ey = np.zeros((len(zvals), self.xsamps, self.ysamps),
                      dtype=np.complex128)
        Ez = np.zeros((len(zvals), self.xsamps, self.ysamps),
                      dtype=np.complex128)
        if self.conf["General"]["compute_h"]:
            Hx = np.zeros((len(zvals), self.xsamps, self.ysamps),
                          dtype=np.complex128)
            Hy = np.zeros((len(zvals), self.xsamps, self.ysamps),
                          dtype=np.complex128)
            Hz = np.zeros((len(zvals), self.xsamps, self.ysamps),
                          dtype=np.complex128)
        else:
            Hx, Hy, Hz = None, None, None
        for zcount, z in enumerate(zvals):
            if self.conf["General"]["compute_h"]:
                E_arr, H_arr = self.s4.GetFieldsOnGridNumpy(z=z,
                                                            NumSamples=(self.ysamps-1,
                                                                        self.xsamps-1))
                Hx[zcount, :-1, :-1] = H_arr[:, :, 0]
                Hx[zcount, 0:self.xsamps-1, -1] = H_arr[:, 0, 0]
                Hx[zcount, -1, 0:self.ysamps-1] = H_arr[0, :, 0]
                Hx[zcount, -1, -1] = H_arr[0, 0, 0]
                Hy[zcount, :-1, :-1] = H_arr[:, :, 1]
                Hy[zcount, 0:self.xsamps-1, -1] = H_arr[:, 0, 1]
                Hy[zcount, -1, 0:self.ysamps-1] = H_arr[0, :, 1]
                Hy[zcount, -1, -1] = H_arr[0, 0, 1]
                Hz[zcount, :-1, :-1] = H_arr[:, :, 2]
                Hz[zcount, 0:self.xsamps-1, -1] = H_arr[:, 0, 2]
                Hz[zcount, -1, 0:self.ysamps-1] = H_arr[0, :, 2]
                Hz[zcount, -1, -1] = H_arr[0, 0, 2]
            else:
                start = time.time()
                E_arr = self.s4.GetFieldsOnGridNumpy(z=z,
                                                     NumSamples=(self.ysamps-1,
                                                                 self.xsamps-1))[0]
                end = time.time()
                self.log.debug('Time for S4 GetFieldsOnGrid call: %f',
                               end-start)
            # Grab the periodic BC, which is always excluded from results
            # returned by S4 above
            Ex[zcount, :-1, :-1] = E_arr[:, :, 0]
            Ex[zcount, 0:self.xsamps-1, -1] = E_arr[:, 0, 0]
            Ex[zcount, -1, 0:self.ysamps-1] = E_arr[0, :, 0]
            Ex[zcount, -1, -1] = E_arr[0, 0, 0]
            Ey[zcount, :-1, :-1] = E_arr[:, :, 1]
            Ey[zcount, 0:self.xsamps-1, -1] = E_arr[:, 0, 1]
            Ey[zcount, -1, 0:self.ysamps-1] = E_arr[0, :, 1]
            Ey[zcount, -1, -1] = E_arr[0, 0, 1]
            Ez[zcount, :-1, :-1] = E_arr[:, :, 2]
            Ez[zcount, 0:self.xsamps-1, -1] = E_arr[:, 0, 2]
            Ez[zcount, -1, 0:self.ysamps-1] = E_arr[0, :, 2]
            Ez[zcount, -1, -1] = E_arr[0, 0, 2]
        self.log.debug('Finished computing fields!')
        return Ex, Ey, Ez, Hx, Hy, Hz

    def compute_fields_by_point(self):
        self.log.debug('Computing fields ...')
        Ex = np.zeros((self.zsamps, self.xsamps, self.ysamps),
                      dtype=np.complex128)
        Ey = np.zeros((self.zsamps, self.xsamps, self.ysamps),
                      dtype=np.complex128)
        Ez = np.zeros((self.zsamps, self.xsamps, self.ysamps),
                      dtype=np.complex128)
        if self.conf["General"]["compute_h"]:
            Hx = np.zeros((self.zsamps, self.xsamps, self.ysamps),
                          dtype=np.complex128)
            Hy = np.zeros((self.zsamps, self.xsamps, self.ysamps),
                          dtype=np.complex128)
            Hz = np.zeros((self.zsamps, self.xsamps, self.ysamps),
                          dtype=np.complex128)
        else:
            Hx, Hy, Hz = None, None, None
        for zcount, z in enumerate(self.Z):
            for i, x in enumerate(self.X):
                for j, y in enumerate(self.Y):
                    E, H = self.s4.GetFields(x, y, z)
                    Ex[zcount, i, j] = E[0]
                    Ey[zcount, i, j] = E[1]
                    Ez[zcount, i, j] = E[2]
                    if self.conf["General"]["compute_h"]:
                        Hx[zcount, i, j] = H[0]
                        Hy[zcount, i, j] = H[1]
                        Hz[zcount, i, j] = H[2]
        return Ex, Ey, Ez, Hx, Hy, Hz

    def compute_fields_at_point(self, x, y, z):
        """
        Compute the electric field at a specific point within the device and
        return a tuple of the components Ex, Ey, Ez
        """

        if self.conf["General"]["compute_h"]:
            E, H = self.s4.GetFields(x, y, z)
        else:
            E = self.s4.GetFields(x, y, z)[0]
            H = (None, None, None)
        return E[0], E[1], E[2], H[0], H[1], H[2]

    def compute_fields_by_layer(self, sample_dict):
        """
        Compute fields within each layer such that a z sample falls exactly on
        the start and end of a layer. The purpose of this it to reduce
        integration errors

        :param sample_dict: A dictionary whose keys are strings of layer names
        and whose values are integers indicating the number of z sampling
        points to use in that layer
        :type sample_dict: dict[str] int
        :return: A dictionary whose keys are layers names, and whose values are
        dictionaries containing all the field components
        :rtype: dict[str] dict
        """

        results = {}
        for lname, layer in self.layers.items():
            if lname not in sample_dict:
                self.log.info("Layer %s not in sample dict, skipping", lname)
                continue
            if isinstance(sample_dict[lname], int):
                z = np.linspace(layer.start, layer.end, sample_dict[lname])
            else:
                args = [layer.start, layer.end, *sample_dict[lname]]
                z = arithmetic_arange(*args)
            self.log.info("Computing fields in layer %s using %i samples",
                          lname, len(z))
            Ex, Ey, Ez, Hx, Hy, Hz = self.compute_fields(zvals=z)
            # results[lname] = {'Ex':Ex, 'Ey':Ey, 'Ez':Ez, 'Hx':Hx, 'Hy':Hy,
            #                   'Hz':Hz}
            results.update({'{}_{}'.format(lname, fname): arr for fname, arr in
                           (('Ex', Ex), ('Ey', Ey), ('Ez', Ez), ('Hx', Hx),
                            ('Hy', Hy), ('Hz', Hz))})
        return results

    # @do_profile(follow=[])
    def compute_fields_on_plane(self, z, xs, ys):
        """
        Compute the electric field on an x-y plane at a given z value with a
        given number of samples in the x and y directions and return a tuple
        containg the 2D arrays of the fields components in (Ex, Ey, Ez) order

        This function is inclusive of the periodic endpoints at x=xmax and y=ymax
        """
        Ex = np.zeros((xs, ys), dtype=np.complex128)
        Ey = np.zeros((xs, ys), dtype=np.complex128)
        Ez = np.zeros((xs, ys), dtype=np.complex128)
        if self.conf["General"]["compute_h"]:
            Hx = np.zeros((xs, ys), dtype=np.complex128)
            Hy = np.zeros((xs, ys), dtype=np.complex128)
            Hz = np.zeros((xs, ys), dtype=np.complex128)
            # E, H = self.s4.GetFieldsOnGrid(z=z, NumSamples=(ys-1,
            #                                                 xs-1),
            #                                Format='Array')
            # E_arr = np.array(E)
            # H_arr = np.array(H)
            E_arr, H_arr = self.s4.GetFieldsOnGridNumpy(z=z,
                                                        NumSamples=(ys-1, xs-1))
        else:
            E_arr = self.s4.GetFieldsOnGridNumpy(z=z,
                                                 NumSamples=(ys-1, xs-1))[0]
            # E = self.s4.GetFieldsOnGrid(z=z, NumSamples=(ys-1, xs-1),
            #                             Format='Array')[0]
            # E_arr = np.array(E)
            # print(E_arr.shape)
            # return E_arr[0, :, :], E_arr[1, :, :], E_arr[2, :, :], None, None, None
            # Grab the periodic BC, which is always excluded from results
            # returned by S4 above
            Ex[:-1, :-1] = E_arr[:, :, 0]
            Ex[0:xs-1, -1] = E_arr[:, 0, 0]
            Ex[-1, 0:ys-1] = E_arr[0, :, 0]
            Ex[-1, -1] = E_arr[0, 0, 0]
            Ey[:-1, :-1] = E_arr[:, :, 1]
            Ey[0:xs-1, -1] = E_arr[:, 0, 1]
            Ey[-1, 0:ys-1] = E_arr[0, :, 1]
            Ey[-1, -1] = E_arr[0, 0, 1]
            Ez[:-1, :-1] = E_arr[:, :, 2]
            Ez[0:xs-1, -1] = E_arr[:, 0, 2]
            Ez[-1, 0:ys-1] = E_arr[0, :, 2]
            Ez[-1, -1] = E_arr[0, 0, 2]
        if self.conf["General"]["compute_h"]:
            H_arr = np.array(H)
            Hx[:-1, :-1] = H_arr[:, :, 0]
            Hx[0:xs-1, -1] = H_arr[:, 0, 0]
            Hx[-1, 0:ys-1] = H_arr[0, :, 0]
            Hx[-1, -1] = H_arr[0, 0, 0]
            Hy[:-1, :-1] = H_arr[:, :, 1]
            Hy[0:xs-1, -1] = H_arr[:, 0, 1]
            Hy[-1, 0:ys-1] = H_arr[0, :, 1]
            Hy[-1, -1] = H_arr[0, 0, 1]
            Hz[:-1, :-1] = H_arr[:, :, 2]
            Hz[0:xs-1, -1] = H_arr[:, 0, 2]
            Hz[-1, 0:ys-1] = H_arr[0, :, 2]
            Hz[-1, -1] = H_arr[0, 0, 2]
        else:
            Hx, Hy, Hz = None, None, None
        return Ex, Ey, Ez, Hx, Hy, Hz

    def get_field(self):
        start = time.time()
        if self.conf['General']['adaptive_convergence']:
            Ex, Ey, Ez, numbasis, conv = self.adaptive_convergence()
            self.data.update({'Ex':Ex,'Ey':Ey,'Ez':Ez})
            self.converged = (conv, numbasis)
        else:
            # Ex, Ey, Ez, Hx, Hy, Hz = self.compute_fields_by_point()
            Ex, Ey, Ez, Hx, Hy, Hz = self.compute_fields()
            if Hx is not None:
                self.data.update({'Ex':Ex,'Ey':Ey,'Ez':Ez,'Hx':Hx,'Hy':Hy,'Hz':Hz})
            else:
                self.data.update({'Ex':Ex,'Ey':Ey,'Ez':Ez})
                # self.data.update({'Ex':Ex.real,'Ey':Ey.real,'Ez':Ez.real})
        end = time.time()
        diff = end - start
        self.log.info("Time to compute fields: %f seconds", diff)

    def update_zsamples(self):
        """
        Update the field arrays stored on disk with data at new z sampling
        points. This is useful if you have changed the location of the sampling
        points, but do not want to delete all the old data, but rather merge
        the two datasets. This will still preserve the regularity of the
        gridded data because the x-y sampling remains unchanged, however the
        gridding may become nonuniform in the z direction
        """
        pbase = '/sim_{}'.format(self.ID[0:10])
        # Make sure we have the field arrays
        if self.conf["General"]["compute_h"]:
            fields = ('Ex', 'Ey', 'Ez', 'Hx', 'Hy', 'Hz')
        else:
            fields = ('Ex', 'Ey', 'Ez')
        self.get_field()
        # Merge the old and the new coordinates, removing duplicates and
        # sorting
        # old_z = self.hdf5.get_node(posixpath.join(pbase, 'zcoords')).read()
        new_z = merge_and_sort(self.Z, old_z)
        old_z_inds = find_inds(old_z, new_z)[0]
        curr_z_inds = find_inds(self.Z, new_z)[0]
        for field in fields:
            fpath = posixpath.join(pbase, field)
            # old_arr = self.hdf5.get_node(fpath)
            old_arr = self.hdf5.get_node(fpath).read()
            new_arr = np.zeros((len(new_z), old_arr.shape[1],
                                old_arr.shape[2]), dtype=np.complex128)
            curr_arr = self.data[field]
            # for i, zi in enumerate(old_z_inds):
            #     new_arr[zi, :, :] = old_arr[i, :, :]
            new_arr[old_z_inds, :, :] = old_arr[:, :, :]
            # for i, zi in enumerate(curr_z_inds):
            #     new_arr[zi, :, :] = curr_arr[i, :, :]
            new_arr[curr_z_inds, :, :] = curr_arr[:, :, :]
            self.data[field] = new_arr
            # self.hdf5.remove_node(fpath)
        self.Z = new_z
        # Keep xy samples from old array
        self.conf['General']['x_samples'] = new_arr.shape[1]
        self.conf['General']['y_samples'] = new_arr.shape[2]
        self.conf['General']['z_samples'] = len(new_z)
        # self.data.update({"xcoords": old_x, "ycoords": old_y, "zcoords":
        #                   new_z})
        self.data.update({"zcoords": new_z})
        # Finally, save the new data
        # for c in ('xcoords', 'ycoords', 'zcoords'):
        #     self.hdf5.remove_node(posixpath.join(pbase, c))
        # self.hdf5.remove_node(posixpath.join(pbase, 'zcoords'))
        # self.save_data()
        self.save_conf()
        # self.hdf5.close()

    def compute_fluxes(self):
        """
        Get the fluxes at the top and bottom of each layer. This is a surface
        integral of the component of the Poynting flux perpendicular to this
        x-y plane of the interface, and have forward and backward components.
        Returns a dict where the keys are the layer name and the values are a
        length 2 tuple with the forward component first and the backward
        component second. The components are complex numbers
        """
        self.log.debug('Computing fluxes ...')
        rows = len(list(self.conf['Layers'].keys()))*2
        dt = [('layer', 'S25'), ('forward', np.complex128), ('backward', np.complex128)]
        flux_arr = np.recarray((rows,), dtype=dt)
        counter = 0
        for layer, ldata in self.conf['Layers'].items():
            self.log.debug('Computing fluxes through layer: %s' % layer)
            # This gets flux at top of layer
            forw, back = self.s4.GetPowerFlux(Layer=layer)
            flux_arr[counter] = (layer, forw, back)
            # This gets flux at the bottom
            offset = ldata['thickness']
            forw, back = self.s4.GetPowerFlux(Layer=layer, zOffset=offset)
            key = layer + '_bottom'
            flux_arr[counter+1] = (key, forw, back)
            counter += 2
        self.log.debug('Finished computing fluxes!')
        return flux_arr

    def get_fluxes(self):
        """
        Convenience method to compute fluxes and store in self.data attribute
        """

        flux_arr = self.compute_fluxes()
        self.data['fluxes'] = flux_arr
        return flux_arr

    def compute_dielectric_profile(self):
        """
        Gets the dielectric profile throughout the device. This is useful for
        determining the resolution of the dielectric profile used by S4. It uses
        the same number of sampling points as specified in the config file for
        retrieiving field data.
        """
        self.log.debug('Computing dielectric profile ...')
        xv, yv = np.meshgrid(self.X, self.Y, indexing='ij')
        z = self.dz
        for layer, ldata in sorted(self.conf['Layers'].items(),
                                   key=lambda tup: tup[1]['order']):
            self.log.debug('Computing epsilon at z = %f in layer %s', z, layer)
            eps_mat = np.zeros((self.xsamps, self.ysamps), dtype=np.complex128)
            for ix in range(self.xsamps):
                for iy in range(self.ysamps):
                    eps_val =  self.s4.GetEpsilon(xv[ix, iy], yv[ix, iy],
                                                  z)
                    eps_mat[ix, iy] = eps_val
            key = 'dielectric_profile_{}'.format(layer)
            self.data[key] = eps_mat
            z += ldata['thickness']
        self.log.debug('Finished computing dielectric profile!')

    def compute_dielectric_profile_at_point(self, x, y, z):
        return self.s4.GetEpsilon(x, y, z)

    def get_q_values(self):
        """
        Returns a dictionary where the keys are names of all the layers in the
        device. The values are numpy arrays containing the 2*N_G q values (i.e
        propagation constants
        """

        self.log.info('Computing q values')
        return_data = {}
        for layer, ldata in self.conf['Layers'].items():
            self.log.debug("Layer: {}".format(layer))
            q_vals = np.array(self.s4.GetPropagationConstants(Layer=layer))
            key = '{}_qvals'.format(layer)
            self.data[key] = q_vals
            return_data[layer] = q_vals
        self.log.info('Finished computing coefficients!')
        return return_data

    def get_fourier_coefficients(self, offset=0.):
        """
        Return a list of the Fourier coefficients used to approximate the
        fields
        """
        self.log.info('Retrieving Fourier coefficients')
        return_data = {}
        for layer, ldata in self.conf['Layers'].items():
            self.log.debug("Layer: {}".format(layer))
            if offset == 0.:
                self.log.debug('Offset zero, not using that arg to avoid bug')
                res = self.s4.GetAmplitudes(Layer=layer)
            else:
                self.log.debug('Using offset')
                res = self.s4.GetAmplitudes(Layer=layer, zOffset=offset)
            forw = np.array(res[0])
            backw = np.array(res[1])
            coeff_arr = np.row_stack((forw, backw))
            key = '{}_amplitudes'.format(layer)
            self.data[key] = coeff_arr
            return_data[layer] = coeff_arr
        self.log.info('Finished computing coefficients!')
        return return_data

    def load_state(self):
        """
        Load solution from disk
        """
        log = logging.getLogger(__name__)
        self.log.info("Loading simulation state")
        sfile = self.conf['General']['solution_file']
        # sfile = 'solution.xml'
        fname = osp.join(self.path, sfile)
        print(fname)
        if osp.isfile(fname):
            self.log.info("Loading from: %s", fname)
            log.info("Simulator %s loading solution from: %s", self.ID[0:10], fname)
            self.s4.LoadSolution(Filename=fname)
            self.log.info("Solution loaded!")
            log.info("Solution loaded!")
        else:
            self.log.warning("Solution file does not exist. Cannot load")
            log.warning("Solution file does not exist. Cannot load")
            # print("Solution file does not exist. Cannot load")

    def save_state(self):
        """
        Save solution to disk
        """
        self.log.info("Saving simulation state")
        sfile = self.conf['General']['solution_file']
        fname = osp.expandvars(osp.join(self.path, sfile))
        self.log.info("Saving to: %s" % fname)
        if osp.isfile(fname):
            self.log.info("State file exists, skipping save")
        else:
            self.s4.SaveSolution(Filename=fname)
            self.log.info("Solution saved!")
        self.s4.SaveSolution(Filename=fname)
        self.log.info("Solution saved!")

    def get_integrals(self):
        raise NotImplementedError("The underlying volume integral functions "
                                  "in S4 are broken. Don't use this function "
                                  " until I fix them")
        self.log.debug('Computing volume integrals')
        integrals = {}
        for layer, ldata in self.conf['Layers'].items():
            self.log.debug('Computing integral through layer: %s' % layer)
            result = self.s4.GetLayerVolumeIntegral(Layer=layer, Quantity='E')
            self.log.debug('Integral = %s', str(result))
            integrals[layer] = result
        print(integrals)
        return integrals

    def save_data(self):
        """
        Writes the data. This is a simple wrapper around the write_data()
        method of the DataManager object, with some code to compute the time it
        took to perform the write operation
        """

        print(list(self.data.keys()))
        if not self.conf['General']['save_as']:
            return
        elif self.conf['General']['save_as'] == 'hdf5':
            start = time.time()
            self.data.write_data(clear=True)
            self.save_time()
            end = time.time()
            self.log.info('Write time: %.2f seconds', end - start)
        else:
            raise ValueError('Invalid value {} in config at'
                             ' General.save_as'.format(self.conf['General']['save_as']))

    def save_conf(self):
        """
        Saves the simulation config object to a file
        """
        path = osp.join(self.path, 'sim_conf.yml')
        self.log.debug('Saving conf to YAML file: %s', path)
        self.conf.write(path)
        if not self.conf['General']['save_as']:
            pass
        elif self.conf['General']['save_as'] == 'hdf5':
            self.log.debug('Saving conf to HDF5 file')
            gname = 'sim_{}'.format(self.ID[0:10])
            try:
                node = self.hdf5.get_node('/'+gname)
            except tb.NoSuchNodeError:
                self.log.warning('You need to create the group for this '
                'simulation before you can set attributes on it. Creating now')
                node = self.hdf5.create_group('/', gname)
            node._v_attrs['conf'] = self.conf.dump()
        else:
            raise ValueError('Invalid value {} in config at'
                             ' General.save_as'.format(self.conf['General']['save_as']))

    def save_time(self):
        """
        Saves the run time for the simulation
        """
        if not self.conf['General']['save_as']:
            pass
        elif self.conf['General']['save_as'] == 'hdf5':
            self.log.debug('Saving runtime to HDF5 file')
            path = '/sim_{}'.format(self.ID[0:10])
            try:
                node = self.hdf5.get_node(path)
            except tb.NoSuchNodeError:
                self.log.warning('You need to create the group for this '
                'simulation before you can set attributes on it. Creating now')
                node = self.hdf5.create_group(path)
            node._v_attrs['runtime'] = self.runtime
        else:
            raise ValueError('Invalid value {} in config at'
                             ' General.save_as'.format(self.conf['General']['save_as']))

    def calc_diff(self, fields1, fields2, exclude=False):
        """Calculate the percent difference between two vector fields"""
        # This list contains three 3D arrays corresponding to the x,y,z
        # componenets of the e field. Within each 3D array is the complex
        # magnitude of the difference between the two field arrays at each
        # spatial point squared
        diffs_sq = [np.absolute(arr1 - arr2)**2 for arr1, arr2 in zip(fields1, fields2)]
        # Sum the squared differences of each component
        mag_diffs = sum(diffs_sq)
        # Now compute the norm(E)^2 of the comparison sim at each sampling
        # point
        normsq = sum([np.absolute(field)**2 for field in fields1])
        # We define the percent difference as the ratio of the sums of the
        # difference vector magnitudes to the comparison field magnitudes,
        # squared rooted.
        # TODO: This seems like a somewhat shitty metric that washes out any
        # large localized deviations. Should test other metrics
        diff = np.sqrt(np.sum(mag_diffs) / np.sum(normsq))
        self.log.debug('Percent difference = {}'.format(diff))
        return diff

    def adaptive_convergence(self):
        """Performs adaptive convergence by checking the error between vector
        fields for simulations with two different numbers of basis terms.
        Returns the field array, last number of basis terms simulated, and a
        boolean representing whether or not the simulation is converged"""
        self.log.debug('Beginning adaptive convergence procedure')
        start_basis = self.conf['Simulation']['numbasis']
        basis_step = self.conf['General']['basis_step']
        ex, ey, ez = self.compute_fields()
        max_diff = self.conf['General']['max_diff']
        max_iter = self.conf['General']['max_iter']
        percent_diff = 100
        iter_count = 0
        while percent_diff > max_diff and iter_count < max_iter:
            new_basis = start_basis + basis_step
            self.log.debug('Checking error between {} and {} basis'
                           ' terms'.format(start_basis, new_basis))
            self.set_basis(new_basis)
            self.build_device()
            self.set_excitation()
            ex2, ey2, ez2 = self.compute_fields()
            percent_diff = self.calc_diff([ex, ey, ex], [ex2, ey2, ez2])
            start_basis = new_basis
            ex, ey, ez = ex2, ey2, ez2
            iter_count += 1
        if percent_diff > max_diff:
            self.log.warning('Exceeded maximum number of iterations')
            return ex2, ey2, ez2, new_basis, False
        else:
            self.log.debug('Converged at {} basis terms'.format(new_basis))
            return ex2, ey2, ez2, new_basis, True

    def mode_solve(self, update=False):
        """Find modes of the system. Supposedly you can get the resonant modes
        of the system from the poles of the S matrix determinant, but I
        currently can't really make any sense of this output"""
        if not update:
            self.configure()
            self.build_device()
        else:
            self.update_thicknesses()
        mant, base, expo = self.s4.GetSMatrixDeterminant()
        self.log.debug('Matissa: %s'%str(mant))
        self.log.debug('Base: %s'%str(base))
        res = mant*base**expo
        self.log.debug('Result: %s'%str(res))

    def save_all(self, update=False):
        """
        Gets all the data for this similation by calling the relevant instance
        methods. Basically just a convenient wrapper to execute all the
        functions defined above
        """

        log = logging.getLogger(__name__)
        # TODO: Split this into a get_all and save_all function. Will give more
        # granular sense of timing and also all getting data without having to
        # save
        start = time.time()
        if update:
            self.update_thicknesses()
        self.save_conf()
        self.load_state()
        # sdict = {"Air": 5, "ITO": 100, "NW_AlShell": 200, "Substrate": 300}
        # sdict = {"Air": 5, "ITO": 10, "NW_AlShell": 20, "Substrate": 30}
        # self.compute_fields_by_layer(sdict)
        sdict = self.conf['General']['sample_dict']
        if sdict:
            results = self.compute_fields_by_layer(sdict)
            self.data.update(results)
        else:
            self.get_field()
        self.get_fluxes()
        self.get_fourier_coefficients()
        self.get_q_values()
        if self.conf['General']['dielectric_profile']:
            self.compute_dielectric_profile()
        self.save_state()
        end = time.time()
        self.runtime = end - start
        self.log.info('Simulation {} completed in {:.2}'
                      ' seconds!'.format(self.ID[0:10], self.runtime))
        self.save_data()
        return None
